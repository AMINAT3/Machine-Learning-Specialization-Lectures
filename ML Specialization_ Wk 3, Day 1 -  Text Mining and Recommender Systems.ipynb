{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["1mrDsUPXk7Y9","0DPlChOElJn9","g1pTeHzEmpIg","tBWq4GruBzav","w2jfHUZAQ6wn","rDm_bUL0hIyk","-Gpqx0s25w-8","uTWMmXspAK_k","2-6Vg7lR8MqD"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Text Mining and Recommender Systems\n","One of the key areas of artificial intelligence is natural language processing (NLP), or\n","text mining as it’s generally known, which deals with teaching computers how to extract\n","meaning from text\n","\n"],"metadata":{"id":"S__4Kw-hsKnU"}},{"cell_type":"markdown","source":["## Text Mining Process Overview\n","The overall text mining process can be broadly categorized into the following four\n","phases, as shown in Figure 5-1:\n","1. Text data assemble\n","2. Text data preprocessing\n","3. Data exploration or visualization\n","4. Model building"],"metadata":{"id":"U5w6bBK6sTeY"}},{"cell_type":"markdown","source":["## Data Assemble (Text)\n","It is observed that 70% of data available to any businesses is unstructured. The first step\n","is collating unstructured data from different sources such as open-ended feedback;\n","phone calls; e-mail support; online chat; and social media networks like Twitter,\n","LinkedIn, and Facebook"],"metadata":{"id":"NU47rpAWsgOX"}},{"cell_type":"markdown","source":["Let’s look at the code for the most widespread formats in the business world: pdf,\n","jpg, and audio file"],"metadata":{"id":"uJjMHhITssmS"}},{"cell_type":"code","source":["!pip install textract"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"TFTMfQLAuqLk","executionInfo":{"status":"ok","timestamp":1666655779885,"user_tz":-60,"elapsed":31639,"user":{"displayName":"Dataset NexusTech","userId":"07175580999036037068"}},"outputId":"3a85df1e-eb0e-48eb-ec98-9cf12dd5310e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting textract\n","  Downloading textract-1.6.5-py3-none-any.whl (23 kB)\n","Collecting beautifulsoup4~=4.8.0\n","  Downloading beautifulsoup4-4.8.2-py3-none-any.whl (106 kB)\n","\u001b[K     |████████████████████████████████| 106 kB 6.1 MB/s \n","\u001b[?25hCollecting argcomplete~=1.10.0\n","  Downloading argcomplete-1.10.3-py2.py3-none-any.whl (36 kB)\n","Collecting pdfminer.six==20191110\n","  Downloading pdfminer.six-20191110-py2.py3-none-any.whl (5.6 MB)\n","\u001b[K     |████████████████████████████████| 5.6 MB 23.8 MB/s \n","\u001b[?25hCollecting SpeechRecognition~=3.8.1\n","  Downloading SpeechRecognition-3.8.1-py2.py3-none-any.whl (32.8 MB)\n","\u001b[K     |████████████████████████████████| 32.8 MB 1.4 MB/s \n","\u001b[?25hCollecting extract-msg<=0.29.*\n","  Downloading extract_msg-0.28.7-py2.py3-none-any.whl (69 kB)\n","\u001b[K     |████████████████████████████████| 69 kB 7.5 MB/s \n","\u001b[?25hRequirement already satisfied: chardet==3.* in /usr/local/lib/python3.7/dist-packages (from textract) (3.0.4)\n","Collecting docx2txt~=0.8\n","  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n","Collecting xlrd~=1.2.0\n","  Downloading xlrd-1.2.0-py2.py3-none-any.whl (103 kB)\n","\u001b[K     |████████████████████████████████| 103 kB 59.9 MB/s \n","\u001b[?25hCollecting six~=1.12.0\n","  Downloading six-1.12.0-py2.py3-none-any.whl (10 kB)\n","Collecting python-pptx~=0.6.18\n","  Downloading python-pptx-0.6.21.tar.gz (10.1 MB)\n","\u001b[K     |████████████████████████████████| 10.1 MB 47.2 MB/s \n","\u001b[?25hCollecting pycryptodome\n","  Downloading pycryptodome-3.15.0-cp35-abi3-manylinux2010_x86_64.whl (2.3 MB)\n","\u001b[K     |████████████████████████████████| 2.3 MB 52.7 MB/s \n","\u001b[?25hRequirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from pdfminer.six==20191110->textract) (2.4.0)\n","Collecting soupsieve>=1.2\n","  Downloading soupsieve-2.3.2.post1-py3-none-any.whl (37 kB)\n","Collecting compressed-rtf>=1.0.6\n","  Downloading compressed_rtf-1.0.6.tar.gz (5.8 kB)\n","Collecting olefile>=0.46\n","  Downloading olefile-0.46.zip (112 kB)\n","\u001b[K     |████████████████████████████████| 112 kB 43.7 MB/s \n","\u001b[?25hCollecting imapclient==2.1.0\n","  Downloading IMAPClient-2.1.0-py2.py3-none-any.whl (73 kB)\n","\u001b[K     |████████████████████████████████| 73 kB 2.9 MB/s \n","\u001b[?25hCollecting tzlocal>=2.1\n","  Downloading tzlocal-4.2-py3-none-any.whl (19 kB)\n","Collecting ebcdic>=1.1.1\n","  Downloading ebcdic-1.1.1-py2.py3-none-any.whl (128 kB)\n","\u001b[K     |████████████████████████████████| 128 kB 54.0 MB/s \n","\u001b[?25hRequirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from python-pptx~=0.6.18->textract) (4.9.1)\n","Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.7/dist-packages (from python-pptx~=0.6.18->textract) (7.1.2)\n","Collecting XlsxWriter>=0.5.7\n","  Downloading XlsxWriter-3.0.3-py3-none-any.whl (149 kB)\n","\u001b[K     |████████████████████████████████| 149 kB 46.5 MB/s \n","\u001b[?25hCollecting pytz-deprecation-shim\n","  Downloading pytz_deprecation_shim-0.1.0.post0-py2.py3-none-any.whl (15 kB)\n","Collecting backports.zoneinfo\n","  Downloading backports.zoneinfo-0.2.1-cp37-cp37m-manylinux1_x86_64.whl (70 kB)\n","\u001b[K     |████████████████████████████████| 70 kB 7.4 MB/s \n","\u001b[?25hCollecting tzdata\n","  Downloading tzdata-2022.5-py2.py3-none-any.whl (336 kB)\n","\u001b[K     |████████████████████████████████| 336 kB 37.0 MB/s \n","\u001b[?25hBuilding wheels for collected packages: docx2txt, compressed-rtf, olefile, python-pptx\n","  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3980 sha256=4980e33d9e5165252db98e2db1f4224cdb83dcc282e77b95f3d0c327734a430b\n","  Stored in directory: /root/.cache/pip/wheels/b7/20/b2/473e3aea9a0c0d3e7b2f7bd81d06d0794fec12752733d1f3a8\n","  Building wheel for compressed-rtf (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for compressed-rtf: filename=compressed_rtf-1.0.6-py3-none-any.whl size=6204 sha256=59c2dab8906a6e6049c576da2437604388f860f3cbb8a09ba58020c135c99dfd\n","  Stored in directory: /root/.cache/pip/wheels/bb/33/88/88ceee84d1b74b391c086bc594d3fcf80800decfbd6e1ff565\n","  Building wheel for olefile (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for olefile: filename=olefile-0.46-py2.py3-none-any.whl size=35432 sha256=2e8f9c82a5dff9e33f176fbf3d0b454860dac83b16b61575c607531b5f203319\n","  Stored in directory: /root/.cache/pip/wheels/84/53/e6/37d90ccb3ad1a3ca98d2b17107e9fda401a7c541ea1eb6a65a\n","  Building wheel for python-pptx (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for python-pptx: filename=python_pptx-0.6.21-py3-none-any.whl size=470951 sha256=3cdeabe7f8496d900ec818e294cb346b5730945b2c1c5a025033ddf064e4d107\n","  Stored in directory: /root/.cache/pip/wheels/a7/ab/f4/52560d0d4bd4055e9261c6df6e51c7b56c2b23cca3dee811a3\n","Successfully built docx2txt compressed-rtf olefile python-pptx\n","Installing collected packages: tzdata, backports.zoneinfo, six, pytz-deprecation-shim, XlsxWriter, tzlocal, soupsieve, pycryptodome, olefile, imapclient, ebcdic, compressed-rtf, xlrd, SpeechRecognition, python-pptx, pdfminer.six, extract-msg, docx2txt, beautifulsoup4, argcomplete, textract\n","  Attempting uninstall: six\n","    Found existing installation: six 1.15.0\n","    Uninstalling six-1.15.0:\n","      Successfully uninstalled six-1.15.0\n","  Attempting uninstall: tzlocal\n","    Found existing installation: tzlocal 1.5.1\n","    Uninstalling tzlocal-1.5.1:\n","      Successfully uninstalled tzlocal-1.5.1\n","  Attempting uninstall: xlrd\n","    Found existing installation: xlrd 1.1.0\n","    Uninstalling xlrd-1.1.0:\n","      Successfully uninstalled xlrd-1.1.0\n","  Attempting uninstall: beautifulsoup4\n","    Found existing installation: beautifulsoup4 4.6.3\n","    Uninstalling beautifulsoup4-4.6.3:\n","      Successfully uninstalled beautifulsoup4-4.6.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","ipython 7.9.0 requires jedi>=0.10, which is not installed.\n","google-api-python-client 1.12.11 requires six<2dev,>=1.13.0, but you have six 1.12.0 which is incompatible.\n","google-api-core 1.31.6 requires six>=1.13.0, but you have six 1.12.0 which is incompatible.\u001b[0m\n","Successfully installed SpeechRecognition-3.8.1 XlsxWriter-3.0.3 argcomplete-1.10.3 backports.zoneinfo-0.2.1 beautifulsoup4-4.8.2 compressed-rtf-1.0.6 docx2txt-0.8 ebcdic-1.1.1 extract-msg-0.28.7 imapclient-2.1.0 olefile-0.46 pdfminer.six-20191110 pycryptodome-3.15.0 python-pptx-0.6.21 pytz-deprecation-shim-0.1.0.post0 six-1.12.0 soupsieve-2.3.2.post1 textract-1.6.5 tzdata-2022.5 tzlocal-4.2 xlrd-1.2.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["six"]}}},"metadata":{}}]},{"cell_type":"code","source":["!pip install pdf2image"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m6SVW7eUPWw2","executionInfo":{"status":"ok","timestamp":1661434989371,"user_tz":-60,"elapsed":4412,"user":{"displayName":"Dataset NexusTech","userId":"07175580999036037068"}},"outputId":"fec0bd99-431c-4ca4-e2d0-c932c41dac65"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pdf2image\n","  Downloading pdf2image-1.16.0-py3-none-any.whl (10 kB)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from pdf2image) (7.1.2)\n","Installing collected packages: pdf2image\n","Successfully installed pdf2image-1.16.0\n"]}]},{"cell_type":"code","source":["!pip install poppler"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zBjzjCqVTxzP","executionInfo":{"status":"ok","timestamp":1661436136824,"user_tz":-60,"elapsed":1773,"user":{"displayName":"Dataset NexusTech","userId":"07175580999036037068"}},"outputId":"5cb3254e-4da7-4db2-efd7-8d378f555c22"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","\u001b[31mERROR: Could not find a version that satisfies the requirement poppler (from versions: none)\u001b[0m\n","\u001b[31mERROR: No matching distribution found for poppler\u001b[0m\n"]}]},{"cell_type":"code","source":["from pdf2image.exceptions import (\n","    PDFInfoNotInstalledError,\n","    PDFPageCountError,\n","    PDFSyntaxError,\n","    \n",")"],"metadata":{"id":"E6XMfqoDSwQ_","colab":{"base_uri":"https://localhost:8080/","height":373},"executionInfo":{"status":"error","timestamp":1666674311817,"user_tz":-60,"elapsed":1323,"user":{"displayName":"Favour Olusanya","userId":"07663144389054108267"}},"outputId":"bac8bea5-aaf6-4095-a93c-1c7e5c09fee4"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-e5d436345c50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m from pdf2image.exceptions import (\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mPDFInfoNotInstalledError\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mPDFPageCountError\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mPDFSyntaxError\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pdf2image'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["from pdf2image import convert_from_path, convert_from_bytes"],"metadata":{"id":"pwQ0LE5FTabE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image1 = convert_from_path('/content/drive/MyDrive/Machine Learning Specialization Script Files/Datasets/pdf/ocr_text.pdf')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":454},"id":"ztGUAjq7S9IY","executionInfo":{"status":"error","timestamp":1661436198260,"user_tz":-60,"elapsed":392,"user":{"displayName":"Dataset NexusTech","userId":"07175580999036037068"}},"outputId":"e3aa82fc-35e7-4c3d-d73e-0fc2e21dee4f"},"execution_count":null,"outputs":[{"output_type":"error","ename":"PDFInfoNotInstalledError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pdf2image/pdf2image.py\u001b[0m in \u001b[0;36mpdfinfo_from_path\u001b[0;34m(pdf_path, userpw, poppler_path, rawdates, timeout)\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0menv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"LD_LIBRARY_PATH\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoppler_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\":\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LD_LIBRARY_PATH\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0mproc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[1;32m    799\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    801\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1550\u001b[0m                             \u001b[0merr_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1551\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pdfinfo': 'pdfinfo'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mPDFInfoNotInstalledError\u001b[0m                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-618b62baa344>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimage1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Machine Learning Specialization Script Files/Datasets/pdf/ocr_text.pdf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pdf2image/pdf2image.py\u001b[0m in \u001b[0;36mconvert_from_path\u001b[0;34m(pdf_path, dpi, output_folder, first_page, last_page, fmt, jpegopt, thread_count, userpw, use_cropbox, strict, transparent, single_file, output_file, poppler_path, grayscale, size, paths_only, use_pdftocairo, timeout, hide_annotations)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mpoppler_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoppler_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_posix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0mpage_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpdfinfo_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdf_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserpw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoppler_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpoppler_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Pages\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;31m# We start by getting the output format, the buffer processing function and if we need pdftocairo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pdf2image/pdf2image.py\u001b[0m in \u001b[0;36mpdfinfo_from_path\u001b[0;34m(pdf_path, userpw, poppler_path, rawdates, timeout)\u001b[0m\n\u001b[1;32m    483\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         raise PDFInfoNotInstalledError(\n\u001b[0;32m--> 485\u001b[0;31m             \u001b[0;34m\"Unable to get page count. Is poppler installed and in PATH?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m         )\n\u001b[1;32m    487\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mPDFInfoNotInstalledError\u001b[0m: Unable to get page count. Is poppler installed and in PATH?"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":445},"id":"AYG4mDe5r0X6","executionInfo":{"status":"error","timestamp":1666655992676,"user_tz":-60,"elapsed":1734,"user":{"displayName":"Dataset NexusTech","userId":"07175580999036037068"}},"outputId":"cbec2c16-2c8f-4be6-eef1-4ba107bb0886"},"outputs":[{"output_type":"error","ename":"MissingFileError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMissingFileError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-055398c3e371>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Extrcting text from two columned pdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtext2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtextract\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Machine Learning Specialization Script Files/Datasets/pdf/two_column.pdf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'eng'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Extracting text from scanned text pdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/textract/parsers/__init__.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(filename, input_encoding, output_encoding, extension, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m# make sure the filename exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMissingFileError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m# get the filename extension, which is something like .docx for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMissingFileError\u001b[0m: The file \"/content/drive/MyDrive/Machine Learning Specialization Script Files/Datasets/pdf/two_column.pdf\" can not be found.\nIs this the right path/to/file/you/want/to/extract.pdf?"]}],"source":["# Example Code for Extracting Data from pdf, jpg, Audio\n","# You can read/learn more about latest updates about textract on their official documents site at http://textract.readthedocs.io/en/latest/\n","\n","import textract\n","\n","# Extracting text from normal pdf\n","text1 = textract.process(r'/content/drive/MyDrive/DS Specializations/ML/Machine Learning Specialization Script Files/Datasets/pdf/raw_text.pdf', language='eng')\n","\n","# Extrcting text from two columned pdf\n","text2 = textract.process('/content/drive/MyDrive/Machine Learning Specialization Script Files/Datasets/pdf/two_column.pdf', language='eng')\n","\n","# Extracting text from scanned text pdf\n","text3 = textract.process('/content/drive/MyDrive/Machine Learning Specialization Script Files/Datasets/pdf/ocr_text.pdf', method='tesseract', language='eng')\n","\n","# Extracting text from jpg\n","text4 = textract.process('/content/drive/MyDrive/Machine Learning Specialization Script Files/Datasets/jpg/raw_text.jpg', method='tesseract',language='eng')\n","\n","# Extracting text from audio file\n","text5 = textract.process('/content/drive/MyDrive/Machine Learning Specialization Script Files/Datasets/wav/raw_text.wav', language='eng')"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Rbs6b0ht80e","executionInfo":{"status":"ok","timestamp":1667283128176,"user_tz":-60,"elapsed":130436,"user":{"displayName":"Dataset NexusTech","userId":"07175580999036037068"}},"outputId":"92303f4f-3ae4-4c26-8f59-0fc17048bf19"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["print(text1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sc_ZmaIuufTb","executionInfo":{"status":"ok","timestamp":1666656009875,"user_tz":-60,"elapsed":549,"user":{"displayName":"Dataset NexusTech","userId":"07175580999036037068"}},"outputId":"d06ba410-da9b-4823-80cf-22d0f4b0deb3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["b\"I\\t\\r \\xc2\\xa0love\\t\\r \\xc2\\xa0word\\t\\r \\xc2\\xa0documents.\\t\\r \\xc2\\xa0They\\t\\r \\xc2\\xa0are\\t\\r \\xc2\\xa0lovely.\\t\\r \\xc2\\xa0They\\t\\r \\xc2\\xa0make\\t\\r \\xc2\\xa0me\\t\\r \\xc2\\xa0so\\t\\r \\xc2\\xa0happy\\t\\r \\xc2\\xa0I\\t\\r \\xc2\\xa0could\\t\\r \\xc2\\xa0smile.\\t\\r \\xc2\\xa0And\\t\\r \\xc2\\xa0\\nthat\\xe2\\x80\\x99s\\t\\r \\xc2\\xa0why\\t\\r \\xc2\\xa0I\\t\\r \\xc2\\xa0wrote\\t\\r \\xc2\\xa0this\\t\\r \\xc2\\xa0package.\\t\\r \\xc2\\xa0\\n\\t\\r \\xc2\\xa0\\n\\nSample text is hard. That\\xe2\\x80\\x99s \\nwhere http://hipsum.co comes \\nin handy. \\n\\n\\t\\r \\xc2\\xa0\\n\\nSemiotics church-key VHS, Truffaut cliche actually vegan. Cray Austin \\npop-up disrupt letterpress, kitsch fixie Cosby sweater cliche craft beer \\nPBR&B. Gentrify cornhole Tonx McSweeney's, Shoreditch keffiyeh \\nethnic Marfa 90's kogi American Apparel. Shabby chic distillery church-\\nkey locavore beard, food truck chillwave sartorial deep v flannel authentic \\nTumblr narwhal kogi organic. Cred vegan jean shorts Banksy forage \\nNeutra dreamcatcher, hashtag Bushwick polaroid pork belly flannel \\nkeytar Portland post-ironic. Cred hoodie vegan, food truck leggings \\nAustin pour-over banjo trust fund before they sold out cray Intelligentsia \\nplaid typewriter. Williamsburg XOXO plaid Carles Austin tofu. \\n\\nCarles Tonx keffiyeh, leggings 90's lo-fi kogi viral semiotics Brooklyn \\nbiodiesel tousled bespoke kitsch. Vinyl Tonx art party Thundercats retro, \\nviral asymmetrical artisan bicycle rights bitters master cleanse Kickstarter \\nYOLO. Seitan street art semiotics twee skateboard, PBR&B VHS hashtag \\nmeh. Thundercats semiotics shabby chic forage single-origin coffee retro, \\n3 wolf moon iPhone mumblecore 90's trust fund Intelligentsia. Beard \\ngluten-free seitan, VHS sartorial pork belly gastropub meh whatever \\nauthentic synth. Beard single-origin coffee irony fixie, before they sold \\n\\n\\x0cout Pitchfork kitsch readymade. Helvetica butcher wayfarers, lomo artisan \\nhashtag Brooklyn four loko fanny pack 90's mustache 8-bit. \\n\\nMeh jean shorts selfies, crucifix selvage Helvetica Carles PBR Vice \\nBanksy roof party master cleanse ugh PBR&B. Lo-fi freegan salvia photo \\nbooth, Wes Anderson skateboard Odd Future. Etsy art party Bushwick \\nkeffiyeh. Pork belly 3 wolf moon butcher mustache. YOLO raw denim lo-\\nfi, hoodie gentrify Schlitz 8-bit sriracha Shoreditch retro brunch. \\nWilliamsburg farm-to-table beard, mlkshk Banksy fap kogi Etsy art party \\nsquid semiotics. XOXO church-key Pitchfork mlkshk irony tote bag. \\n\\nFarm-to-table brunch tattooed hoodie keytar, literally selvage authentic \\ntrust fund deep v Thundercats Kickstarter narwhal locavore. Swag disrupt \\nchambray, leggings shabby chic gastropub YOLO plaid hoodie \\nWilliamsburg Godard mixtape. Retro Godard keytar biodiesel, freegan \\npaleo Etsy you probably haven't heard of them Pitchfork Schlitz \\nreadymade small batch cred. Pug trust fund paleo, 90's fixie typewriter \\nnext level banjo. Banksy occupy authentic master cleanse Bushwick \\nfingerstache selfies, direct trade craft beer cliche +1 cray. Locavore four \\nloko biodiesel Neutra chia mlkshk. Fanny pack YOLO Portland, mlkshk \\nPBR&B single-origin coffee drinking vinegar 8-bit flannel gentrify \\nstumptown pop-up. \\nOh. You need a little dummy text for your mockup? How quaint. \\n\\nI bet you\\xe2\\x80\\x99re still using Bootstrap too\\xe2\\x80\\xa6 \\n\\n\\t\\r \\xc2\\xa0\\n\\n\\x0c\"\n"]}]},{"cell_type":"code","source":["print(text2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TW3ZNO1GukPp","executionInfo":{"status":"ok","timestamp":1661427205216,"user_tz":-60,"elapsed":649,"user":{"displayName":"Dataset NexusTech","userId":"07175580999036037068"}},"outputId":"023add94-ca6f-4594-f7f9-afa7f0aa12a4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["b'LETTERS\\n\\nVol 465 | 3 June 2010 | doi:10.1038/nature09040\\n\\nThe role of mentorship in prote\\xc2\\xb4ge\\xc2\\xb4 performance\\n\\nR. Dean Malmgren1,2, Julio M. Ottino1,3 & Lu\\xc4\\xb1\\xc2\\xb4s A. Nunes Amaral1,3,4\\n\\nThe role of mentorship in prote\\xc2\\xb4ge\\xc2\\xb4 performance is a matter of import-\\nance to academic, business and governmental organizations.\\nAlthough the benefits of mentorship for prote\\xc2\\xb4ge\\xc2\\xb4s, mentors and their\\norganizations are apparent1\\xe2\\x80\\x939, the extent to which prote\\xc2\\xb4ge\\xc2\\xb4s mimic\\ntheir mentors\\xe2\\x80\\x99 career choices and acquire their mentorship skills is\\nunclear10\\xe2\\x80\\x9316. The importance of a science, technology, engineering\\nand mathematics workforce to economic growth and the role of\\neffective mentorship in maintaining a \\xe2\\x80\\x98healthy\\xe2\\x80\\x99 such workforce\\ndemand the study of the role of mentorship in academia. Here we\\ninvestigate one aspect of mentor emulation by studying mentorship\\nfecundity\\xe2\\x80\\x94the number of prote\\xc2\\xb4ge\\xc2\\xb4s a mentor trains\\xe2\\x80\\x94using data\\nfrom the Mathematics Genealogy Project17, which tracks the mentor-\\nship record of thousands of mathematicians over several centuries.\\nWe demonstrate that fecundity among academic mathematicians is\\ncorrelated with other measures of academic success. We also find\\nthat the average fecundity of mentors remains stable over 60 years of\\nrecorded mentorship. We further discover three significant correla-\\ntions in mentorship fecundity. First, mentors with low mentorship\\nfecundities train prote\\xc2\\xb4ge\\xc2\\xb4s that go on to have mentorship fecundities\\n37% higher than expected. Second, in the first third of their careers,\\nmentors with high fecundities train prote\\xc2\\xb4ge\\xc2\\xb4s that go on to have\\nfecundities 29% higher than expected. Finally, in the last third of\\ntheir careers, mentors with high fecundities train prote\\xc2\\xb4ge\\xc2\\xb4s that go on\\nto have fecundities 31% lower than expected.\\n\\nA large literature supports the hypothesis that prote\\xc2\\xb4ge\\xc2\\xb4s and mentors\\nbenefit from the mentoring relationship1,2. Prote\\xc2\\xb4ge\\xc2\\xb4s that receive career\\ncoaching and social support, for instance, are reportedly more likely to\\nhave high performance ratings, a higher salary and receive promo-\\ntions1,3. In return, mentors receive fulfilment not only by altruistically\\nimproving the welfare of their prote\\xc2\\xb4ge\\xc2\\xb4s, but also by improving their own\\nwelfare4,5,10. Organizations benefit as well, because prote\\xc2\\xb4ge\\xc2\\xb4s are more\\nlikely to be committed to their organization6,7 and to exhibit organiza-\\ntional citizenship behaviour6. These benefits are not obtained only\\nthrough the traditional dyadic mentor\\xe2\\x80\\x93prote\\xc2\\xb4ge\\xc2\\xb4 relationship, but also\\nthrough peer relationships that supplement prote\\xc2\\xb4ge\\xc2\\xb4 development8,9.\\n\\nThe benefits of mentorship underscore the importance of under-\\nstanding how mentors were in turn trained to foster the development\\nof outstanding mentors. It might be suspected that prote\\xc2\\xb4ge\\xc2\\xb4s learn\\nmanagerial approaches and motivational techniques from their men-\\ntors and, as a result, emulate their mentorship methodologies; this\\nsuggests that outstanding mentors are trained by other outstanding\\nmentors. This possibility is sometimes formalized as the rising-star\\nhypothesis11,12; it postulates that mentors select up-and-coming pro-\\nte\\xc2\\xb4ge\\xc2\\xb4s on the basic of their perceived ability and potential and past\\nperformance10,13,14, including promotion history and proactive career\\nbehaviours12. Rising-star prote\\xc2\\xb4ge\\xc2\\xb4s are reportedly more likely to\\nintend to mentor, resulting in a \\xe2\\x80\\x98perpetual cycle\\xe2\\x80\\x99 of rising-star pro-\\nte\\xc2\\xb4ge\\xc2\\xb4s that emulate their mentors by seeking other rising stars as their\\nprote\\xc2\\xb4ge\\xc2\\xb4s15.\\n\\nHowever, there is conflicting evidence concerning the rising-star\\nhypothesis16, so the extent to which prote\\xc2\\xb4ge\\xc2\\xb4s mimic their mentors\\n\\nremains an open question. Indeed, we are unaware of any studies that\\nsystematically track mentorship success over the entire career of a\\nmentor, so the validity of the rising-star hypothesis has yet to be fully\\nexplored. Here we investigate whether prote\\xc2\\xb4ge\\xc2\\xb4s acquire the mentor-\\nship skills of their mentors, by studying mentorship fecundity, that is,\\nthe number of prote\\xc2\\xb4ge\\xc2\\xb4s that a mentor trains over the course of their\\ncareer. This measure is advantageous as it directly measures an out-\\ncome of the mentorship process that is relevant to sustained mentor-\\nship, allowing us to quantify the degree to which mentor fecundity\\ndetermines prote\\xc2\\xb4ge\\xc2\\xb4 fecundity.\\n\\nScientific mentorship offers a unique opportunity to study this\\nquestion because there is a structured mentorship environment\\nbetween advisor and student that is, in principle, readily accessible18,19.\\nWe study a prototypical mentorship network collected from the\\nMathematics Genealogy Project17, which aggregates the graduation\\ndate, mentor and prote\\xc2\\xb4ge\\xc2\\xb4s of 114,666 mathematicians from as early\\nas 1637. This database is unique in its scope and coverage, tracking the\\ncareer-long mentorship record of a large population of mentors in a\\nsingle discipline (see the MPACT Project (http://ils.unc.edu/mpact/)\\nfor a smaller database of theses on information and library sciences\\nand references therein). From this information, we construct a net-\\nwork in which links are formed from a mentor to each of his k pro-\\nte\\xc2\\xb4ge\\xc2\\xb4s, where k denotes mentorship fecundity. We focus here on the\\n7,259 mathematicians who graduated between 1900 and 1960, because\\ntheir mentorship record is the most reliable (Methods).\\n\\nAlthough the mentorship records gathered from the Mathematics\\nGenealogy Project provide the most comprehensive data source avail-\\nable for the study of academic performance throughout a mathemati-\\ncian\\xe2\\x80\\x99s career, there are obviously other plausible metrics for evaluating\\nacademic performance20\\xe2\\x80\\x9322. We have also compared the mentorship\\ndata against a list of publications for 4,447 mathematicians and a list of\\n269 inductees into the US National Academy of Sciences (NAS;\\nMethods). We find that mentorship fecundity is much larger for\\nNAS members than for non-NAS members (Fig. 1a). We further find\\nthat the number of publications is strongly correlated with fecundity,\\nregardless of whether or not a mathematician is an NAS member\\n(Fig. 1b). These results demonstrate that although fecundity is not a\\ntypical measure of academic performance, it is closely related to other\\nmeasures of academic success. Thus, even though our investigation\\nconcerns how fecundity is correlated between mentor and prote\\xc2\\xb4ge\\xc2\\xb4, our\\nresults also address questions in the academic evaluation literature\\nconcerning the success of a mathematician.\\n\\nWe first investigate whether it is possible to predict the fecundity of\\na mathematician by modelling the empirical fecundity distribution,\\np(kjt), as a function of graduation year, t. Considering that some\\nmathematicians remain in academia throughout their careers whereas\\nothers spend only a portion of their careers in academia, it might be\\nexpected that there are two types of individual when it comes to\\nacademic mentorship fecundity\\xe2\\x80\\x94\\xe2\\x80\\x98haves\\xe2\\x80\\x99 and \\xe2\\x80\\x98have-nots\\xe2\\x80\\x99\\xe2\\x80\\x94in the\\nsense that mathematicians from these types respectively have or have\\nnot had the opportunity to mentor students throughout their career.\\n\\n1Department of Chemical and Biological Engineering, Northwestern University, Evanston, Illinois 60208, USA. 2Datascope Analytics, Evanston, Illinois 60201, USA. 3Northwestern\\nInstitute on Complex Systems, Northwestern University, Evanston, Illinois 60208, USA. 4Howard Hughes Medical Institute, Northwestern University, Evanston, Illinois 60208, USA.\\n\\n622\\n\\n\\xc2\\xa92010\\n\\nMacmillan Publishers Limited. All rights reserved\\n\\n\\x0cNATURE | Vol 465 | 3 June 2010\\n\\nLETTERS\\n\\nb\\n\\nc\\n\\nP = 0.626\\n\\nP = 0.758\\n\\nP = 0.068\\n\\n10\\n\\n20\\n\\n30\\n\\n0\\n\\n10\\n\\n40 50 0\\n\\n10 20 30 40 50\\n\\n20\\n\\n30\\n\\nFecundity, k\\n\\na\\n\\ni\\n\\nn\\no\\ni\\nt\\nu\\nb\\ni\\nr\\nt\\ns\\nd\\n \\ne\\nv\\ni\\nt\\na\\nu\\nm\\nu\\nC\\n\\nl\\n\\nd\\n\\n100\\n\\n10\\xe2\\x80\\x931\\n\\n10\\xe2\\x80\\x932\\n\\n10\\xe2\\x80\\x933\\n0\\n\\nh\\n\\xcf\\x80\\n\\ne\\n\\nh\\n\\xce\\xba\\n\\nf\\n\\n0.6\\n0.5\\n0.4\\n0.3\\n0.2\\n0.1\\n0.0\\n20\\n\\n15\\n\\n10\\n\\n5\\n0\\n2.0\\n\\n1.5\\n\\n0.5\\n0.0\\n\\nn\\nh\\n\\xce\\xba\\n\\n1.0\\n\\na\\n\\n100\\n\\ni\\n\\nn\\no\\ni\\nt\\nu\\nb\\ni\\nr\\nt\\ns\\nd\\n \\ne\\nv\\ni\\nt\\na\\nu\\nm\\nu\\nC\\n\\nl\\n\\n10\\xe2\\x80\\x931\\n\\n10\\xe2\\x80\\x932\\n\\n10\\xe2\\x80\\x933\\n\\nb\\n\\n103\\n\\ns\\nn\\no\\ni\\nt\\na\\nc\\n\\ni\\nl\\n\\nb\\nu\\np\\n\\n \\nf\\no\\n \\nr\\ne\\nb\\nm\\nu\\nN\\n\\n102\\n\\n101\\n\\n10\\xe2\\x80\\x934\\n0\\n\\n20\\n\\n40\\n\\n60\\n\\n80\\n\\n100\\n\\n100\\n100\\nFecundity, k\\n\\n101\\n\\n102\\n\\nFigure 1 | Relationship between mentorship fecundity and other\\nperformance metrics. a, Cumulative distribution of the mentorship\\nfecundity for NAS members (red) and non-NAS members (black). NAS\\nmembers have an average fecundity of \\xc3\\x86k\\xc3\\xa6NAS 5 14, which is far greater than\\nthe average fecundity of non-NAS members, \\xc3\\x86k\\xc3\\xa6non-NAS 5 3.1, indicating that\\nfecundity is closely related to academic recognition. Not all mathematicians\\nin the non-NAS group were eligible for NAS membership, owing to\\ncitizenship and other circumstances. This fact makes the result in the figure\\nall the more striking. b, Average number of publications as a function of the\\nmentorship fecundity, for NAS members (red) and non-NAS members\\n(black). NAS members have nearly twice as many publications on average as\\nnon-NAS members for all fecundity levels. Error bars, 1 s.e.\\n\\nIf each mentor chooses to train a new academic prote\\xc2\\xb4ge\\xc2\\xb4 with\\nprobability jh or jhn, and stops training academic prote\\xc2\\xb4ge\\xc2\\xb4s otherwise,\\ndepending on whether they are a \\xe2\\x80\\x98have\\xe2\\x80\\x99 or, respectively, a \\xe2\\x80\\x98have-not\\xe2\\x80\\x99,\\nthen we would expect that the resulting fecundity distribution is a\\nmixture of two discrete exponential distributions\\n\\naverage\\n\\nrespective\\n\\np(kjH)~php(kjkh)z(1{ph)p(kjkhn)\\n\\n\\xc3\\xb01\\xc3\\x9e\\nwherephistheprobabilitythatamathematicianisa\\xe2\\x80\\x98have\\xe2\\x80\\x99andp(kjkh)and\\np(kjkhn) are discrete exponential distributions p(kjk) 5 e2k/k(1 2 e21/k)\\nwith\\nand\\n21) for \\xe2\\x80\\x98haves\\xe2\\x80\\x99 and \\xe2\\x80\\x98have-nots\\xe2\\x80\\x99. We estimate the\\nkhn 5 1/ln(jhn\\nparameters H 5 {ph, kh, khn} of this distribution from the empirical\\ndata using expectation maximization23. Using Monte Carlo hypo-\\nthesis testing (Methods), we have found that equation (1) cannot be\\nrejected as a candidate description of the fecundity distribution p(kjt)\\n(Fig. 2a\\xe2\\x80\\x93c). For an alternative description of p(kjt), see Supplementary\\nDiscussion and Supplementary Fig. 1.\\n\\nkh 5 1/ln(jh\\n\\nfecundities\\n\\n21)\\n\\nAs might be expected, the probability, ph, that an individual is a\\n\\xe2\\x80\\x98have\\xe2\\x80\\x99 experiences drastic changes over time as a result of historical\\nevents, such as the First and Second World Wars, the beginning of the\\nCold War and considerable increases in academic funding (Fig. 2d).\\nIn contrast, the average fecundities of \\xe2\\x80\\x98haves\\xe2\\x80\\x99 and \\xe2\\x80\\x98have-nots\\xe2\\x80\\x99 do not\\nexhibit systematic historical changes, suggesting that these quantities\\noffer fundamental insight into the mentorship process among math-\\nematicians (Fig. 2e, f). For the sixty year period considered, we find\\nthat (cid:1)kkh 5 9.8 6 0.4 and (cid:1)kkhn 5 0.47 6 0.03, where the overbar indi-\\ncates a time average of the respective average fecundity.\\n\\nThe stationarity of kh and khn also provides a simple heuristic for\\nclassifying an individual as a \\xe2\\x80\\x98have\\xe2\\x80\\x99 or a \\xe2\\x80\\x98have-not\\xe2\\x80\\x99; by maximum\\nlikelihood, an individual is a \\xe2\\x80\\x98have\\xe2\\x80\\x99 if k $ 2 and is a \\xe2\\x80\\x98have-not\\xe2\\x80\\x99 other-\\nwise. These results raise the possibility that similar features, perhaps\\nwith different characteristic scales of fecundity, may be present in\\nother mentorship domains.\\n\\nAlthough our description of the fecundity distribution has high-\\nlighted a fundamental property of mentorship among mathematicians,\\nit is not predictive of the behaviour of individual mathematicians in the\\nsense that fecundity, according to this model, is a random variable\\ndrawn from the distribution in equation (1). We next test whether\\nprote\\xc2\\xb4ge\\xc2\\xb4s mimic the mentorship fecundity of their mentors, by com-\\nparing prote\\xc2\\xb4ge\\xc2\\xb4 fecundity with a suitable null model that does not\\nintroduce correlations in fecundity. As in the study of genealogical\\ntrees, we perform comparisons of the empirical data with networks\\n\\n\\xc2\\xa92010\\n\\nMacmillan Publishers Limited. All rights reserved\\n\\n1900\\n\\n1920\\n\\n1940\\n\\n1960\\n\\n1980\\n\\n2000\\n\\nGraduation year, t\\n\\nFigure 2 | Evolution of the fecundity distribution. a\\xe2\\x80\\x93c, Cumulative\\ndistribution of the fecundity of mathematicians that graduated during 1910\\n(a), 1930 (b) and 1950 (c) (symbols), compared with the best-estimate\\npredictions of a mixture of two discrete exponentials (lines). Monte Carlo\\nhypothesis testing confirms that this model can not be rejected as a model of\\nthe fecundity distribution during every year from 1900\\xe2\\x80\\x931960, as denoted by\\nthe P values above the a 5 0.05 significance level (Methods). d\\xe2\\x80\\x93f, Best-\\nestimate parameters as functions of time, calculated by maximum likelihood\\nfor a mixture of two discrete exponentials. Dashed lines denote average\\nparameter values between 1900 and 1960 and coloured circles indicate the\\nyears displayed in panels a\\xe2\\x80\\x93c. The probability, ph, of being a \\xe2\\x80\\x98have\\xe2\\x80\\x99 changes\\nover time, generally in relation to historic events (hashed grey shading\\nindicates the First and Second World Wars). In contrast, the average\\nfecundities remain stable, with time-average values of (cid:1)kkh 5 9.8 6 0.4 and\\n(cid:1)kkhn 5 0.47 6 0.03, until 1960, the time at which mentorship records become\\nincomplete (Methods), and then steadily decrease (grey shaded region).\\n\\ngenerated from uncorrelated branching processes in our investigation\\nof the mathematician genealogy network. Here graduation date is\\nequivalent to birth date and mentors and prote\\xc2\\xb4ge\\xc2\\xb4s are equivalent to\\nparents and children, respectively.\\n\\nIn a branching process24, a parent p, born at time tp, has kp children.\\nChild c of parent p is born at time tc and subsequently has kc children.\\nThe fecundity, k, of each individual is drawn from the conditional\\nfecundity distribution p(kjt) for an individual born at time t.\\nNetworks generated from this type of branching process are therefore\\ndefined by the birth date of each individual, t, the fecundity distri-\\nbution p(kjt), and the chronology of child births, {tc}, for each parent\\n(Fig. 3a).\\n\\nWe compare the mathematician genealogy network with two\\nensembles of randomized genealogies from the branching process\\nfamily. Random networks from ensemble I retain the birth date of each\\nindividual, the fecundity of each individual and the chronology of child\\nbirths for each parent (Fig. 3b), as above. Random networks from\\nensemble II additionally restrict parent\\xe2\\x80\\x93child pairs to have the same\\nage difference, tc 2 tp, as parent\\xe2\\x80\\x93child pairs in the empirical network\\n(Fig. 3c). All other attributes of these networks are randomized using a\\nlink-switching algorithm25,26 (Methods), so neither of these random-\\nnetwork ensembles introduces correlations between parent fecundity\\nand child fecundity or temporal correlations in fecundity. They there-\\nfore provide a suitable basis for comparison with the mathematician\\ngenealogy network.\\n\\n623\\n\\n\\x0cLETTERS\\n\\nNATURE | Vol 465 | 3 June 2010\\n\\nK. A. Hirsch\\n\\nB. A. Griffith\\n\\nW. Tollmien\\n\\nH. D. Kloosterman\\n\\na\\n\\nk\\nr\\no\\nw\\nt\\ne\\nn\\n\\n \\nl\\na\\nc\\ni\\nr\\ni\\np\\nm\\nE\\n\\nb\\n\\nl\\n\\nI\\n \\ne\\nb\\nm\\ne\\ns\\nn\\ne\\n \\ng\\nn\\ni\\nt\\na\\nr\\ne\\nn\\ne\\nG\\n\\nc\\n\\nl\\n\\nI\\nI\\n \\ne\\nb\\nm\\ne\\ns\\nn\\ne\\n \\ng\\nn\\ni\\nt\\na\\nr\\ne\\nn\\ne\\nG\\n\\nsignificance of any differences between the empirical data and the null\\nmodels.\\n\\nWe use the partitioning of children into classes to examine the\\nrelationship between the average child fecundity, \\xc3\\x86kc\\xc3\\xa6, and the age\\ndifference, tc 2 tp, between parent and child (Fig 4a, b and Supplemen-\\ntary Fig. 4a, b). If the data were consistent with a branching process,\\nthen we would expect \\xc3\\x86kc\\xc3\\xa6 to have no temporal dependence. However,\\nthe regressions between the \\xc3\\x86kc\\xc3\\xa6 z-score (Methods) and tc 2 tp deviate\\nsignificantly (Fig. 4c and Supplementary Fig. 4c) from this expectation\\nfor both random ensembles, to reveal three distinct features. First,\\nmentors with kp , 3 train prote\\xc2\\xb4ge\\xc2\\xb4s that go on to have mentorship\\nfecundities 37% higher than expected throughout their careers.\\nSecond, in the first third of their careers, mentors with kp $ 10 train\\nprote\\xc2\\xb4ge\\xc2\\xb4s that go on to have fecundities 29% higher than expected.\\nFinally, in the last third of their careers, mentors with kp $ 10 train\\nprote\\xc2\\xb4ge\\xc2\\xb4s that go on to have fecundities 31% lower than expected.\\n\\nThe fact that mentors with k , 3 train prote\\xc2\\xb4ge\\xc2\\xb4s with higher-than-\\nexpected fecundities throughout their careers is somewhat counter-\\nintuitive. From the rising-star hypothesis11,12, it might be expected\\nthat prote\\xc2\\xb4ge\\xc2\\xb4s trained by mentors with k , 3 are likely to mimic their\\nmentors and therefore have lower-than-expected fecundities. Our\\nresults demonstrate that this is not the case. One possible explanation\\nis that mentors with k , 3 are more aware of the resources they must\\nallocate for effective mentorship, leading to a more enriching men-\\ntorship experience for their prote\\xc2\\xb4ge\\xc2\\xb4s. An alternative hypothesis is that\\nmentors with k , 3 select for, or are selected by, prote\\xc2\\xb4ge\\xc2\\xb4s that have a\\ngreater aptitude for mentorship.\\n\\nThe striking temporal correlations for mentors with kp $ 10 are\\nalso intriguing. Because mentors with kp $ 10 represent the upper\\nechelon of mentors in mathematics, these mentors were probably\\n\\xe2\\x80\\x98rising stars\\xe2\\x80\\x99 early in their academic careers. The fact that these men-\\ntors train prote\\xc2\\xb4ge\\xc2\\xb4s with high fecundities early in their careers sup-\\nports the rising-star hypothesis.\\n\\nBy the end of these mentors\\xe2\\x80\\x99 careers, however, their prote\\xc2\\xb4ge\\xc2\\xb4s have\\nlower-than-expected fecundities. Perhaps mentors, who ultimately\\nhave high fecundities, spend fewer and fewer resources training each\\nof their prote\\xc2\\xb4ge\\xc2\\xb4s as their careers progress. Alternatively, prote\\xc2\\xb4ge\\xc2\\xb4s with\\nhigh mentorship fecundity aspirations might court prolific mentors\\nearly in their mentors\\xe2\\x80\\x99 careers whereas prote\\xc2\\xb4ge\\xc2\\xb4s with low fecundity\\naspirations might court prolific mentors later in their mentors\\xe2\\x80\\x99 careers.\\nOur findings therefore reveal interesting nuances to the rising-star\\nhypothesis.\\n\\nIt is unclear whether the temporal correlations we discover in men-\\ntorship fecundity generalize beyond mathematicians in academia.\\nAnecdotally, mathematicians are thought to perform their best work\\nat a young age27, a perception that may influence how mentors and\\nprote\\xc2\\xb4ge\\xc2\\xb4s choose each other. Perceptions in other domains, however,\\nmay differ and subsequently influence mentor and prote\\xc2\\xb4ge\\xc2\\xb4 selection in\\ndifferent ways. As data for other academic disciplines18,19, business and\\nthe government becomes available, it will be important to determine\\nwhether temporal correlations in fecundity are a general consequence\\nof mentorship or are a particular consequence of mentorship for\\nmathematicians in academia.\\n\\nRegardless, our results offer another means of judging academic\\nimpact in science as well as the impact of managers on their employ-\\nees, both of which are notoriously complicated and risky affairs.\\nThese assessments are multidimensional, metrics and expectations\\nare domain dependent, and placement of creative output, timescales\\nof impact and recognition vary significantly from field to field.\\nUltimately, the assessment of individuals for awards and promotion\\nis based on painstaking individual analysis by selection committees\\nand peers. Although these committees may have varying goals and\\nincentives, it is important that collective arguments\\xe2\\x80\\x94the kind of\\narguments we are making here\\xe2\\x80\\x94be based on sound quantitative\\nanalysis. Although the extent to which our findings extrapolate to\\nother domains may vary, we are confident that the kind of analysis\\n\\n1920\\n\\n1930\\n\\n1960\\n\\n1970\\n\\n1940\\n1950\\nGraduation year, t\\n\\nFigure 3 | Branching process null models. a, Subset of the mathematician\\ngenealogy network. Mentors/parents (black circles) are connected to each of\\ntheir prote\\xc2\\xb4ge\\xc2\\xb4s/children (white circles). The horizontal positions of\\nmathematicians represent their graduation/birth dates, t. The bottom two\\nparents were born in 1924, the top two parents were born in 1937, and all\\nfour parents have a child born in 1958. From a parent\\xe2\\x80\\x99s perspective, three\\nessential features of the empirical network must be preserved in random\\nnetworks generated from the two branching process null models: the birth\\ndate, tp, the fecundity, kp, and the chronology of child births, {tc}. b, Random\\nnetworks from ensemble I preserve these three essential features. Solid red\\nlines highlight the links in the empirical network whose end points can be\\nrandomized. Dashed red lines illustrate one of the possible randomization\\nmoves after switching the corresponding pair of links. We note that the age\\ndifference between parent and child is not preserved. c, Random networks\\nfrom ensemble II preserve the three essential features as well as the age\\ndifference between parent and child. Solid blue lines of the same colour\\nhighlight the links in the empirical network whose end points can be\\nrandomized. Dashed blue lines illustrate one of the possible randomization\\nmoves after switching the corresponding pair of links. Random networks for\\neach ensemble are generated by attempting 100 switches per link (Methods).\\n\\nTo explore the influence of mentor fecundity and age difference on\\nprote\\xc2\\xb4ge\\xc2\\xb4 fecundity, we partition prote\\xc2\\xb4ge\\xc2\\xb4s according to the fecundity of\\ntheir mentors and the age difference between mentor and prote\\xc2\\xb4ge\\xc2\\xb4,\\ntc 2 tp. Given our findings (Supplementary Discussion and Sup-\\nplementary Figs 2 and 3), it is clear that age differences affect fecundity\\nin a nonrandom manner for prote\\xc2\\xb4ge\\xc2\\xb4s whose mentors have kp , 3. We\\npartition the remaining prote\\xc2\\xb4ge\\xc2\\xb4s, whose mentors have kp $ 3, into two\\ngroups: prote\\xc2\\xb4ge\\xc2\\xb4s whose mentors\\n\\xe2\\x80\\x98haves\\xe2\\x80\\x99\\n(3 # kp , 10) and prote\\xc2\\xb4ge\\xc2\\xb4s whose mentors are above-average \\xe2\\x80\\x98haves\\xe2\\x80\\x99\\n(kp $ 10). We then partition these three groups of prote\\xc2\\xb4ge\\xc2\\xb4s according\\nto when they graduated during their mentors\\xe2\\x80\\x99 careers. Specifically,\\nwe split each group of prote\\xc2\\xb4ge\\xc2\\xb4s into terciles, the most fine-grained\\ngrouping that still gives us sufficient power to examine the statistical\\n\\nare below-average\\n\\n624\\n\\n\\xc2\\xa92010\\n\\nMacmillan Publishers Limited. All rights reserved\\n\\n\\x0cNATURE | Vol 465 | 3 June 2010\\n\\nLETTERS\\n\\nkp < 3\\n\\n3 \\xe2\\x89\\xa4 kp < 10\\n\\nkp \\xe2\\x89\\xa5 10\\n\\n\\xe2\\x8c\\xaa\\n\\xe2\\x8c\\xa9k\\n= 2.2\\nE\\n\\xe2\\x8c\\xaa\\n\\xe2\\x8c\\xa9k\\n= 2.6\\nM\\n\\xe2\\x8c\\xa9k\\n\\xe2\\x8c\\xaa = 1.2\\n\\nL\\n\\n\\xe2\\x8c\\xaa\\n\\xe2\\x8c\\xa9k\\nE\\n\\xe2\\x8c\\xaa\\n\\xe2\\x8c\\xa9k\\nM\\n\\xe2\\x8c\\xa9k\\n\\xe2\\x8c\\xaa\\nL\\n\\n= 1.7\\n= 0.8\\n= 1.3\\n\\n\\xe2\\x8c\\xa9k\\n\\xe2\\x8c\\xaa\\nE\\n\\xe2\\x8c\\xaa\\n\\xe2\\x8c\\xa9k\\nM\\n\\xe2\\x8c\\xa9k\\n\\xe2\\x8c\\xaa\\nL\\n\\n= 2.5\\n= 0.8\\n= 0.3\\n\\n10\\n\\n20\\n\\n30\\n\\n40\\n\\n0\\n\\n40\\n\\n0\\n\\n10\\n\\n20\\n\\n30\\n\\n40\\n\\n20\\n\\n10\\n30\\nChild fecundity, kc\\n\\nSlope, 0.023\\nIntercept, 0.18\\n\\nSlope, 0.026\\nIntercept, \\xe2\\x80\\x930.42\\n\\nSlope, \\xe2\\x80\\x930.10\\nIntercept, 2.1\\n\\n10\\n\\n20\\n\\n30\\n\\n40\\n\\n20\\n\\n10\\n\\n40\\nAge difference, tc \\xe2\\x80\\x93 tp (yr)\\n\\n30\\n\\n10\\n\\n20\\n\\n30\\n\\n40\\n\\n100\\n\\n10\\xe2\\x80\\x931\\n\\n10\\xe2\\x80\\x932\\n\\n10\\xe2\\x80\\x933\\n0\\n\\na\\n\\ni\\n\\nn\\no\\ni\\nt\\nu\\nb\\ni\\nr\\nt\\ns\\nd\\n \\ne\\nv\\ni\\nt\\na\\nu\\nm\\nu\\nC\\n\\nl\\n\\nb\\n\\ne\\nr\\no\\nc\\ns\\n-\\n\\nz\\n\\n \\n\\n\\xe2\\x8c\\xaa\\n\\nc\\n\\nk\\n\\xe2\\x8c\\xa9\\n\\nc\\n\\nt\\np\\ne\\nc\\nr\\ne\\nt\\nn\\n\\nI\\n\\n4\\n\\n2\\n\\n0\\n\\n\\xe2\\x80\\x932\\n\\n\\xe2\\x80\\x934\\n\\n3\\n\\n2\\n\\n1\\n\\n0\\n\\n\\xe2\\x80\\x931\\n\\n\\xe2\\x80\\x932\\n\\n\\xe2\\x80\\x933\\n\\nEns. I\\nEarly\\nMiddle\\nLate\\n\\n1900s\\n1910s\\n1920s\\n1930s\\n1940s\\n1950s\\n\\n102\\n\\n101\\n\\n100\\n\\nP\\nr\\no\\nb\\na\\nb\\n\\ni\\nl\\ni\\nt\\ny\\n \\nd\\ne\\nn\\ns\\ni\\nt\\ny\\n\\nP = 0.009\\n\\nP = 0.366\\n\\nP < 0.001\\n\\n\\xe2\\x80\\x930.1\\n\\n0.0\\n\\n0.1\\n\\n\\xe2\\x80\\x930.1\\n\\n0.1\\n\\n\\xe2\\x80\\x930.1\\n\\n0.0\\n\\n0.1\\n\\n0.0\\n\\nSlope\\n\\nFigure 4 | Effect of age difference between mentor and prote\\xc2\\xb4ge\\xc2\\xb4, tc 2 tp, on\\nprote\\xc2\\xb4ge\\xc2\\xb4 fecundity. a, Fecundity distribution of children born during the\\n1910s (for which the average fecundity was 1.4) to parents with kp , 3,\\n3 # kp , 10 and kp $ 10, compared with the expectation from ensemble I\\n(grey line). We separate children into terciles (early, middle, late) according\\nto tc 2 tp, and denote the average fecundities of the children born early,\\nmiddle and late in their parents\\xe2\\x80\\x99 lives as \\xc3\\x86kE\\xc3\\xa6, \\xc3\\x86kM\\xc3\\xa6 and \\xc3\\x86kL\\xc3\\xa6, respectively. The\\naverage fecundity of children born to parents with kp , 3 is higher than\\nexpected, regardless of whether they were born during the early, middle or\\nlater part of their parents\\xe2\\x80\\x99 lives. We also note that the average fecundity of\\nchildren born to parents with kp $ 10 decreases throughout their parents\\xe2\\x80\\x99\\nlives. b, We quantify the significance of these trends during each decade\\n(coloured symbols) by computing the z-score of the average child fecundity,\\n\\xc3\\x86kc\\xc3\\xa6, compared with the average child fecundity in networks from ensemble I.\\nThis information is summarized by identifying the linear regression (solid\\n\\nblack line; slope and intercept as shown). The regression lines for networks\\nfrom our null model (grey lines) vary around the expectation of our null\\nmodel (dashed black line). c, Significance of linear regressions in b. We\\ncompare the slope and intercept of the empirical regression (black circle)\\nwith the distribution of the slope and intercept of the same quantities\\ncomputed from the null model. Because these quantities are approximately\\ndistributed as a multivariate Gaussian, we compute the equivalent of a two-\\ntailed P value by finding the fraction of synthetically generated\\nslope\\xe2\\x80\\x93intercept pairs that lie outside the equiprobability surface of the\\nmultivariate Gaussian (dashed ellipse). The slopes and intercepts of the\\nregressions for children of parents with low (P 5 0.009) and high (P , 0.001)\\nfecundities are significantly different from the expectations for the null\\nmodel, consistent with the data displayed in a. Comparisons with\\nexpectations from random networks from ensemble II yield the same\\nconclusions (Supplementary Fig. 4).\\n\\npresented here will serve to elevate the discourse on scientific and\\nmanagerial impact.\\n\\nMETHODS SUMMARY\\nData acquisition. We use data from the Mathematics Genealogy Project17 to\\nidentify the 7,259 prote\\xc2\\xb4ge\\xc2\\xb4 mathematicians that are in the giant component28 and\\ngraduated between 1900 and 1960, of which 4,447 have linked publication\\nrecords through the American Mathematical Society\\xe2\\x80\\x99s research database\\nMathSciNet. We use a text-matching algorithm29 to semi-automatically match\\nmembers of the NAS with mathematicians from the Mathematics Genealogy\\nProject.\\nMonte Carlo hypothesis testing for p(kjt). We use Monte Carlo hypothesis\\ntesting30 to determine whether equation (1) with maximum-likelihood23 para-\\nmeters H can be rejected as a candidate model for p(kjt) at the a 5 0.05 signifi-\\ncance level.\\nRandom-network generation. We use a variation of the Markov chain Monte\\nCarlo algorithm25,26 to construct each of the 1,000 random networks in ensembles\\nI and II. Specifically, we restrict the switching of end points of links p R c that\\nbelong to the same link class L, where the link classes are defined as\\nLI(t) 5 {p R cjtc 5 t} and LII(s, t) 5 {p R cjtp 5 s, tc 5 t} for networks\\nfrom\\nensembles I and II, respectively. Each link class can be thought of as a subgraph,\\nwhich can then be randomized in the usual way by attempting 100 switches per\\nlink in the class25,26.\\n\\nAverage-fecundity z-score. By the central limit theorem, the average of variates\\ndrawn from p(kcjtc) is normally distributed because p(kcjtc) is well described by a\\nmixture of discrete exponential distributions that has finite variance. Given a set\\nof child fecundities, Kc 5 {kc}, we quantify how significantly a subset of these\\nchild fecundities, Kc* , Kc, deviates from Kc by measuring the z-score of \\xc3\\x86kc\\xc3\\xa6, the\\naverage child fecundity of all nodes within the subset Kc*, compared with \\xc3\\x86kc\\xc3\\xa6s,\\nthe average child fecundity computed for children within a subset equivalent to\\nKc* in the synthetic networks. That is, we compute z 5 (\\xc3\\x86kc\\xc3\\xa6 2 m)/s, where m is\\nthe ensemble average of {\\xc3\\x86kc\\xc3\\xa6s} and s is the standard deviation of the ensemble\\n{\\xc3\\x86kc\\xc3\\xa6s} over the 1,000 realizations generated for our null models.\\n\\nFull Methods and any associated references are available in the online version of\\nthe paper at www.nature.com/nature.\\n\\nReceived 21 December 2009; accepted 19 March 2010.\\n\\n1.\\n\\nKram, K. E. Mentoring at Work: Developmental Relationships in Organizational Life\\n(Scott Foresman, 1985).\\n\\n2. Chao, G. T., Walz, P. M. & Gardner, P. D. Formal and informal mentorships: a\\n\\ncomparison on mentoring functions and contrast with nonmentored\\ncounterparts. Person. Psychol. 45, 619\\xe2\\x80\\x93635 (1992).\\nScandura, T. A. Mentorship and career mobility: an empirical investigation. J.\\nOrgan. Behav. 13, 169\\xe2\\x80\\x93174 (1992).\\n\\n3.\\n\\n4. Aryee, S., Chay, Y. W. & Chew, J. The motivation to mentor among managerial\\n\\nemployees. Group Organ. Manage. 21, 261\\xe2\\x80\\x93277 (1996).\\n\\n\\xc2\\xa92010\\n\\nMacmillan Publishers Limited. All rights reserved\\n\\n625\\n\\n\\x0cLETTERS\\n\\nNATURE | Vol 465 | 3 June 2010\\n\\n5. Allen, T. D., Poteet, M. L., Russell, J. E. A. & Dobbins, G. H. A field study of factors\\nrelated to supervisors\\xe2\\x80\\x99 willingness to mentor others. J. Vocat. Behav. 50, 1\\xe2\\x80\\x9322 (1997).\\n6. Donaldson, S. I., Ensher, E. A. & Grant-Vallone, E. J. Longitudinal examination of\\nmentoring relationships on organizational commitment and citizenship behavior.\\nJ. Career Dev. 26, 233\\xe2\\x80\\x93249 (2000).\\nPayne, S. C. & Huffman, A. H. A longitudinal examination of the influence of\\nmentoring on organizational commitment and turnover. Acad. Manage. J. 48,\\n158\\xe2\\x80\\x93168 (2005).\\n\\n7.\\n\\n8. Kram, K. E. & Isabella, L. A. Mentoring alternatives: the role of peer relationships in\\n\\ncancer development. Acad. Manage. J. 28, 110\\xe2\\x80\\x93132 (1985).\\n\\n9. Higgins, M. C. & Kram, K. E. Reconceptualizing mentoring at work: a\\n\\ndevelopmental network perspective. Acad. Manage. Rev. 26, 264\\xe2\\x80\\x93283 (2001).\\n\\n10. Allen, T. D., Poteet, M. L. & Burroughs, S. M. The mentor\\xe2\\x80\\x99s perspective: a\\n\\nqualitative inquiry and future research agenda. J. Vocat. Behav. 51, 70\\xe2\\x80\\x9389 (1997).\\n11. Green, S. G. & Bauer, T. N. Supervisory mentoring by advisers: relationships with\\n\\ndoctoral student potential, productivity, and commitment. Person. Psychol. 48,\\n537\\xe2\\x80\\x93562 (1995).\\n\\n12. Singh, R., Ragins, B. R. & Tharenou, P. Who gets a mentor? A longitudinal\\n\\nassessment of the rising star hypothesis. J. Vocat. Behav. 74, 11\\xe2\\x80\\x9317 (2009).\\n\\n13. Allen, T. D., Poteet, M. L. & Russell, J. E. A. Prote\\xc2\\xb4ge\\xc2\\xb4 selection by mentors: what\\n\\nmakes the difference? J. Organ. Behav. 21, 271\\xe2\\x80\\x93282 (2000).\\n\\n14. Allen, T. D. Prote\\xc2\\xb4ge\\xc2\\xb4 selection by mentors: contributing individual and\\n\\norganizational factors. J. Vocat. Behav. 65, 469\\xe2\\x80\\x93483 (2004).\\n\\n15. Ragins, B. R. & Scandura, T. A. Burden or blessing? Expected costs and benefits of\\n\\nbeing a mentor. J. Organ. Behav. 20, 493\\xe2\\x80\\x93509 (1999).\\n\\n16. Paglis, L. L., Green, S. G. & Bauer, T. N. Does adviser mentoring add value? A\\n\\nlongitudinal study of mentoring and doctoral student outcomes. Res. High. Ed. 47,\\n451\\xe2\\x80\\x93476 (2006).\\n\\n17. North Dakota State University. The Mathematics Genealogy Project \\xc3\\x86http://\\n\\ngenealogy.math.ndsu.nodak.edu\\xc3\\xa6 (accessed, November 2007).\\n\\n18. Bourne, P. E. & Fink, J. L. I am not a scientist, I am a number. PLoS Comput. Biol. 4,\\n\\ne1000247 (2008).\\n\\n19. Enserink, M. Are you ready to become a number? Science 323, 1662\\xe2\\x80\\x931664 (2009).\\n20. King, J. A review of bibliometric and other science indicators and their role in\\n\\nresearch evaluation. J. Inf. Sci. 13, 261\\xe2\\x80\\x93276 (1987).\\n\\n21. Moed, H. F. Citation Analysis in Research Evaluation (Springer, 2005).\\n22. Hirsch, J. E. An index to quantify an individual\\xe2\\x80\\x99s scientific research output. Proc.\\n\\nNatl Acad. Sci. USA 102, 16569\\xe2\\x80\\x9316572 (2005).\\n\\n23. Bishop, C. M. Pattern Recognition and Machine Learning (Springer, 2007).\\n24. Athreya, K. B. & Ney, P. E. Branching Processes (Courier Dover, 2004).\\n25. Milo, R., Kashtan, N., Itzkovitz, S., Newman, M. E. J. & Alon, U. On the uniform\\n\\ngeneration of random graphs with prescribed degree sequences. Preprint at\\n\\xc3\\x86http://arxiv.org/abs/cond-mat/0312028\\xc3\\xa6 (2004).\\nItzkovitz, S., Milo, R., Kashtan, N., Newman, M. E. J. & Alon, U. Reply to \\xe2\\x80\\x98\\xe2\\x80\\x98Comment\\non \\xe2\\x80\\x98Subgraphs in random networks\\xe2\\x80\\x99\\xe2\\x80\\x99\\xe2\\x80\\x99. Phys. Rev. E 70, 058102 (2004).\\n\\n26.\\n\\n27. Hardy, G. H. A Mathematician\\xe2\\x80\\x99s Apology (Cambridge Univ. Press, 1940).\\n28. Stauffer, D. & Aharony, A. Introduction to Percolation Theory 2nd edn (Taylor &\\n\\nFrancis, 1992).\\n\\n29. Chapman, B. & Chang, J. Biopython: python tools for computational biology. ACM\\n\\nSIGBIO Newslett. 20, 15\\xe2\\x80\\x9319 (2000).\\n\\n30. D\\xe2\\x80\\x99Agostino, R. B. & Stephens, M. A. Goodness-of-Fit Techniques (Dekker, 1986).\\n\\nSupplementary Information is linked to the online version of the paper at\\nwww.nature.com/nature.\\n\\nAcknowledgements We thank R. Guimera`, P. McMullen, A. Pah, M. Sales-Pardo,\\nE. N. Sawardecker, D. B. Stouffer and M. J. Stringer for comments and suggestions.\\nL.A.N.A. gratefully acknowledges the support of US National Science Foundation\\nawards SBE 0830388 and IIS 0838564. All figures were generated using\\nPYGRACE (http://pygrace.sourceforge.net) with colour schemes from\\nColorBrewer 2.0 (http://colorbrewer.org).\\n\\nAuthor Contributions R.D.M. analyzed data, designed the study and wrote the\\npaper. J.M.O. and L.A.N.A. designed the study and wrote the paper.\\n\\nAuthor Information Reprints and permissions information is available at\\nwww.nature.com/reprints. The authors declare no competing financial interests.\\nReaders are welcome to comment on the online version of this article at\\nwww.nature.com/nature. Correspondence and requests for materials should be\\naddressed to J.M.O. (jm-ottino@northwestern.edu) or L.A.N.A.\\n(amaral@northwestern.edu).\\n\\n626\\n\\n\\xc2\\xa92010\\n\\nMacmillan Publishers Limited. All rights reserved\\n\\n\\x0cdoi:10.1038/nature09040\\n\\nMETHODS\\nMathematics Genealogy Project data. We study a prototypical mentorship\\nnetwork collected from the Mathematics Genealogy Project17, which aggregates\\nthe graduation dates, mentors and advisees of 114,666 mathematicians from as\\nearly as 1637. From this information, we construct a mathematician genealogy\\nnetwork in which links are formed from a mentor to each of his or her k prote\\xc2\\xb4ge\\xc2\\xb4s.\\nThe data collected by the Mathematics Genealogy Project are self-reported, so\\nthere is no guarantee that the observed genealogy network is a complete descrip-\\ntion of the mentorship network. In fact, 16,147 mathematicians do not have a\\nrecorded mentor and, of these, 8,336 do not have any recorded prote\\xc2\\xb4ge\\xc2\\xb4s. To\\navoid having these mathematicians distort our analysis, we restrict our analysis\\nto the 90,211 mathematicians that comprise the giant component28 of the net-\\nwork; that is, we restrict our analysis to the largest set of connected mathema-\\nticians in the mathematician genealogy network.\\n\\nAlthough the Mathematics Genealogy Project contains information on math-\\nematicians from as early as 1637, this does not necessarily indicate that all of these\\nrecords are representative of the evolution of the network. For example, before\\n1900 the Project records fewer than 52 new graduates per year worldwide.\\nFurthermore, because mathematicians often have mentorship careers lasting\\n50 years or more, we are not guaranteed to have complete mentorship records\\nfor mathematicians who graduated after 1960. We therefore restrict our analysis\\nto the 7,259 prote\\xc2\\xb4ge\\xc2\\xb4 mathematicians who graduated between 1900 and 1960, for\\nwhom we believe that the graduation and mentorship record is the most reliable.\\nMathSciNet data. Of the 7,259 prote\\xc2\\xb4ge\\xc2\\xb4 mathematicians that graduated between\\n1900 and 1960, 4,447 of them have linked MathSciNet publication records,\\nwhich are used in our analysis.\\nUS National Academy of Science data. The US National Academy of Science\\nmaintains two databases of its membership. The first database consists of all\\ndeceased members elected to the NAS from as early as 1863. This database\\nrecords the name of the inductee, their election year, their date of death and a\\nlink to a biographical sketch. The second database consists of all active members\\nof the NAS. This database records the name of the inductee, their institution,\\ntheir academic field and their election year.\\n\\nThe challenge to matching this data with the Mathematics Genealogy Project\\ndata is that there is no direct link between a member of the NAS and the\\nMathematics Genealogy Project, and vice versa. This is further confounded by\\nthe fact that some members of the NAS have the same name. To circumvent these\\nproblems, we use a text-matching algorithm29 to semi-automatically detect whether\\na member of the NAS matches a name in the Mathematics Genealogy Project\\ndatabase. We use this procedure to curate the 269 members of the NAS that\\ndefinitively match mathematicians in the Mathematics Genealogy Project database.\\nMonte Carlo hypothesis testing for p(kjt). Given a model, M, with parameters\\nHt for the empirically observed fecundity distribution, p(kjt), we use Monte\\nCarlo hypothesis testing to determine whether it can be rejected as a candidate\\nmodel for p(kjt) (ref. 30). The Monte Carlo hypothesis testing procedure is as\\nfollows. First, we calculate the best-estimate parameters, ht, for model M at time t\\n\\nusing maximum-likelihood estimation23. Second, we compute the test statistic, S\\n(detailed below), between the model M(Ht) and the empirical fecundity distri-\\nbution, p(kjt). Next, we generate a synthetic fecundity distribution, ps(k), from\\nmodel M(Ht) using the best-estimate parameters, ht, and we treat the synthetic\\ndata exactly the same as we treated the empirical data: first, we calculate the best-\\nestimate parameters, Hs, for model M from maximum-likelihood estimation;\\nsecond, we compute the test statistic, Ss, between the model M(Hs) and the\\nsynthetic fecundity distribution, ps(k). We generate synthetic fecundity distribu-\\ntions and their corresponding synthetic test statistics until we accumulate an\\nensemble of 1,000 Monte Carlo test statistics, {Ss}. Finally, we calculate a two-\\ntailed P value with a precision of 0.001. As is customary in hypothesis testing, we\\nreject the model M at time t if the P value is less than a threshold value. We select a\\nP-value threshold of 0.05; that is, if less than 5% of the synthetic data sets exhibit\\ndeviations in the test statistic that are larger than those observed empirically, the\\nmodel is rejected at time t.\\nBecause we are conducting hypothesis tests with the fecundity distribution\\np(kjt), which is a distribution with a discrete support, it is important to use a test\\nstatistic S that is appropriate for testing discrete distributions. We use the x2 test\\nstatistic whereby we bin p(kjt) such that each bin has at least one expected\\nobservation according to the model M(Ht). This binning prevents observations\\nthat are exceptionally rare from dominating our statistical test and skewing our\\nresults.\\nRandom-network generation. We use the Markov chain Monte Carlo algo-\\nrithm25,26 to build random networks from the mathematician genealogy net-\\nwork. The standard version of\\nthis algorithm inherently preserves the\\nfecundity of each individual, but it does not preserve the chronology of child\\nbirths, {tc}, for each parent. To obtain random networks belonging to ensemble I\\nor ensemble II, we restrict the switching of end points of links p that belong to the\\nsame link class L, where the link classes are defined as LI(t) 5 {p R cjtc 5 t} and\\nLII(s, t) 5 {p R cjtp 5 s, tc 5 t} for networks from ensembles I and II, respectively.\\nEach link class can be thought of as a subgraph, which can then be randomized\\nusing the Markov chain Monte Carlo algorithm. Here, we attempt 100 switches\\nper link in each link class, which sufficiently alters random networks away from\\nthe original empirical network25,26. We repeat this procedure 1,000 times to\\ngenerate a set of 1,000 random networks for each ensemble.\\nAverage-fecundity z-score. The average of variates drawn from p(kcjtc) is normally\\ndistributed because p(kcjtc) is well described by a mixture of discrete exponential\\ndistributions\\xe2\\x80\\x94a distribution with finite variance\\xe2\\x80\\x94and, thus, the central limit\\ntheorem applies. Given a set of child fecundities, Kc 5 {kc}, we quantify how\\nsignificantly a subset, Kc*, of these child fecundities deviates from Kc, by measuring\\nthe z-score of \\xc3\\x86kc\\xc3\\xa6, the average child fecundity of all nodes within the subset Kc*,\\ncompared with \\xc3\\x86kc\\xc3\\xa6s, the average child fecundity computed for children within a\\nsubset equivalent to Kc* in the synthetic networks. That is, we compute\\nz 5 (\\xc3\\x86kc\\xc3\\xa6 2 m)/s, where m is the ensemble average of {\\xc3\\x86kc\\xc3\\xa6s} ands is the standard\\ndeviation of the ensemble {\\xc3\\x86kc\\xc3\\xa6s} over the 1,000 realizations generated for our null\\nmodels.\\n\\n\\xc2\\xa92010\\n\\nMacmillan Publishers Limited. All rights reserved\\n\\n\\x0c'\n"]}]},{"cell_type":"code","source":["print(text3)"],"metadata":{"id":"No_fBi9_uw7_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(text5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5F1rrRvdu0db","executionInfo":{"status":"ok","timestamp":1661427217182,"user_tz":-60,"elapsed":634,"user":{"displayName":"Dataset NexusTech","userId":"07175580999036037068"}},"outputId":"3cc22a4f-4bfe-47b8-b040-d67d3425f735"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["b'Everything Is Awesome\\n'\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"iKYRuU0bx2p7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Social Media\n","Did you know that Twitter, the online news and social networking service provider, has\n","320 million users, with an average of 42 million active Tweets every day! (Source: Global\n","social media research summary 2016 by smart insights)\n","Let’s understand how to explore the rich information of social media (I’ll consider\n","Twitter as an example) to explore what is being spoken about a chosen topic (Figure 5-2).\n","Most of these forums provide API for developers to access the posts"],"metadata":{"id":"1mrDsUPXk7Y9"}},{"cell_type":"markdown","source":["## Data Preprocessing (Text)\n","This step deals with cleansing the consolidated text to remove noise, to ensure efficient\n","syntactic, semantic text analysis for deriving meaningful insights from the text. Some\n","common cleaning steps are briefed described in the following.\n","\n","- Convert to Lower Case and Tokenize\n","  - Sentence Tokenizing\n","  - Word Tokenizing\n","- Removing Noise\n","- Part of Speech (PoS) Tagging\n","- Stemming\n","- Lemmatization\n","- N-grams\n","- Bag of Words"],"metadata":{"id":"0DPlChOElJn9"}},{"cell_type":"markdown","source":["### Sentence Tokenizing\n","The NLTK (Natural Language Toolkit) library provides sent_tokenize for sentence level\n","tokenizing, which uses a pretrained model, PunktSentenceTokenize, to determine\n","punctuation and characters marking the end of the sentence for European languages "],"metadata":{"id":"g1pTeHzEmpIg"}},{"cell_type":"code","source":["!pip install nltk"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"viXGlXEonlxY","executionInfo":{"status":"ok","timestamp":1661762756314,"user_tz":-60,"elapsed":4237,"user":{"displayName":"Dataset NexusTech","userId":"07175580999036037068"}},"outputId":"a76b9b74-28d4-410a-d893-1e6696070171"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.1.0)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.6.2)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.0)\n"]}]},{"cell_type":"code","source":["# Example Code for Sentence Tokenizing\n","import nltk\n","nltk.download('popular')\n","from nltk.tokenize import sent_tokenize"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8VUV7ZI_k90J","executionInfo":{"status":"ok","timestamp":1661762771455,"user_tz":-60,"elapsed":15154,"user":{"displayName":"Dataset NexusTech","userId":"07175580999036037068"}},"outputId":"b89f0eea-b2a0-4377-ee55-68e5f9f3b55d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading collection 'popular'\n","[nltk_data]    | \n","[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/cmudict.zip.\n","[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n","[nltk_data]    | Downloading package genesis to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/genesis.zip.\n","[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n","[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/inaugural.zip.\n","[nltk_data]    | Downloading package movie_reviews to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n","[nltk_data]    | Downloading package names to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/names.zip.\n","[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n","[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/stopwords.zip.\n","[nltk_data]    | Downloading package treebank to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/treebank.zip.\n","[nltk_data]    | Downloading package twitter_samples to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n","[nltk_data]    | Downloading package omw to /root/nltk_data...\n","[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n","[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n","[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n","[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n","[nltk_data]    | Downloading package words to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/words.zip.\n","[nltk_data]    | Downloading package maxent_ne_chunker to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n","[nltk_data]    | Downloading package punkt to /root/nltk_data...\n","[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n","[nltk_data]    | Downloading package snowball_data to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package averaged_perceptron_tagger to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n","[nltk_data]    | \n","[nltk_data]  Done downloading collection popular\n"]}]},{"cell_type":"code","source":["text=''''Statistics skills, and programming skills are equally important\n","for analytics. Statistics skills and domain knowledge are important for\n","analytics. I like reading books and traveling.'''\n","\n","sent_tokenize_list = sent_tokenize(text)\n","print(sent_tokenize_list)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xVgQIpPxm-kb","executionInfo":{"status":"ok","timestamp":1661441660902,"user_tz":-60,"elapsed":413,"user":{"displayName":"Dataset NexusTech","userId":"07175580999036037068"}},"outputId":"0e0b5bdc-3be7-4617-a6c8-219789c57308"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[\"'Statistics skills, and programming skills are equally important\\nfor analytics.\", 'Statistics skills and domain knowledge are important for\\nanalytics.', 'I like reading books and traveling.']\n"]}]},{"cell_type":"code","source":["#Sentence Tokenizing for European Languages\n","\n","import nltk.data\n","spanish_tokenizer = nltk.data.load('tokenizers/punkt/spanish.pickle')\n","spanish_tokenizer.tokenize('Hola. Esta es una frase espanola.')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gtxPyyGhoA9p","executionInfo":{"status":"ok","timestamp":1661442192212,"user_tz":-60,"elapsed":392,"user":{"displayName":"Dataset NexusTech","userId":"07175580999036037068"}},"outputId":"3b67b54e-1924-4397-c318-6912464132bf"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Hola.', 'Esta es una frase espanola.']"]},"metadata":{},"execution_count":26}]},{"cell_type":"markdown","source":["# Word Tokenizing\n","The word_tokenize function of NLTK is a wrapper function that calls tokenize by the TreebankWordTokenizer"],"metadata":{"id":"TPG5tRUstLpE"}},{"cell_type":"code","source":["#Example Code for Word Tokenizing\n","\n","from nltk.tokenize import word_tokenize\n","print (word_tokenize(text))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sY2xm3o0qXOK","executionInfo":{"status":"ok","timestamp":1661442326176,"user_tz":-60,"elapsed":598,"user":{"displayName":"Dataset NexusTech","userId":"07175580999036037068"}},"outputId":"c51f299d-40fe-4856-c10f-fabe4b3b3996"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[\"'Statistics\", 'skills', ',', 'and', 'programming', 'skills', 'are', 'equally', 'important', 'for', 'analytics', '.', 'Statistics', 'skills', 'and', 'domain', 'knowledge', 'are', 'important', 'for', 'analytics', '.', 'I', 'like', 'reading', 'books', 'and', 'traveling', '.']\n"]}]},{"cell_type":"markdown","source":["# Removing Noise\n","You should remove all information that is not comparative or relevant to text analytics.\n","This can be seen as noise to the text analytics.\n",". Most common noises are numbers,\n","punctuations, stop words, white space, etc."],"metadata":{"id":"YMsN83F0u1f5"}},{"cell_type":"markdown","source":["Numbers: Numbers are removed, as they may not be relevant and not hold valuable\n","information."],"metadata":{"id":"3ql2KaaoxLrD"}},{"cell_type":"code","source":["import regex as re\n","\n","def remove_numbers(text):\n"," return re.sub(r'\\d+', \"\", text)\n","\n","text = 'This is a sample English sentence, \\n with whitespace and numbers 1234!'\n","print ('Removed numbers: ', remove_numbers(text))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XhUNo_zErfn5","executionInfo":{"status":"ok","timestamp":1661762156583,"user_tz":-60,"elapsed":704,"user":{"displayName":"Dataset NexusTech","userId":"07175580999036037068"}},"outputId":"d448ef19-6ccd-4e02-eade-633fbd9be6be"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Removed numbers:  This is a sample English sentence, \n"," with whitespace and numbers !\n"]}]},{"cell_type":"markdown","source":["Punctuation: It is to be removed to better identify each word and remove\n","punctuation characters from the data set. For example: “like,” and “like” or “coca-cola”\n","and “CocaCola” would be interpreted as different words if the punctuation was not\n","removed"],"metadata":{"id":"ZmlfMqgUxU93"}},{"cell_type":"code","source":["# Example Code for Removing Punctuations from Text\n","\n","import string\n","\n","# Function to remove punctuations\n","def remove_punctuations(text):\n"," words = nltk.word_tokenize(text)\n"," punt_removed = [w for w in words if w.lower() not in string.punctuation]\n"," return \" \".join(punt_removed)\n","\n","print (remove_punctuations('This is a sample English sentence, with punctuations!'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RiubelNxvHKq","executionInfo":{"status":"ok","timestamp":1661950071345,"user_tz":-60,"elapsed":6,"user":{"displayName":"Dataset NexusTech","userId":"07175580999036037068"}},"outputId":"8b51c830-208c-4dda-e8d8-575d462a2242"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["This is a sample English sentence with punctuations\n"]}]},{"cell_type":"markdown","source":["Stop words: Words like “the,” “and,” and “or” are uninformative and add unneeded\n","noise to the analysis. For this reason, they are removed"],"metadata":{"id":"DEvB9LCc2Ty2"}},{"cell_type":"code","source":["# Example Code for Removing Stop Words from the Text\n","\n","from nltk.corpus import stopwords\n","\n","# Function to remove stop words\n","def remove_stopwords(text, lang='english'):\n"," words = nltk.word_tokenize(text)\n"," lang_stopwords = stopwords.words(lang)\n"," stopwords_removed = [w for w in words if w.lower() not in lang_stopwords]\n"," return \" \".join(stopwords_removed)\n","\n"," \n","print (remove_stopwords('This is a sample English sentence'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BLNG5PlzxnTn","executionInfo":{"status":"ok","timestamp":1661764684148,"user_tz":-60,"elapsed":573,"user":{"displayName":"Dataset NexusTech","userId":"07175580999036037068"}},"outputId":"e8d97879-5a5c-4e86-fbcf-b5a43003d4bc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["sample English sentence\n"]}]},{"cell_type":"code","source":["print('Python is included in CodeSpeedy \\r123456')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NbLA82KL5MQd","executionInfo":{"status":"ok","timestamp":1661765804040,"user_tz":-60,"elapsed":543,"user":{"displayName":"Dataset NexusTech","userId":"07175580999036037068"}},"outputId":"b6e5fc24-9c94-46ee-cfe9-b02dbf33cc2d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Python is included in CodeSpeedy \r123456\n"]}]},{"cell_type":"code","source":["print('Python is included in CodeSpeedy\\n123456')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gbRGTY-88GJj","executionInfo":{"status":"ok","timestamp":1661765463070,"user_tz":-60,"elapsed":826,"user":{"displayName":"Dataset NexusTech","userId":"07175580999036037068"}},"outputId":"074633a3-f563-4f4b-f0ef-8c24644d85ca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Python is included in CodeSpeedy\n","123456\n"]}]},{"cell_type":"markdown","source":["Whitespace: Often in text analytics, extra whitespace (space, tab, carriage return,\n","line feed) becomes identified as a word. This anomaly is avoided through a basic\n","programming procedure in this step"],"metadata":{"id":"anxnHNKC-UWU"}},{"cell_type":"code","source":["# Example Code for Removing Whitespace from Text\n","# Function to remove whitespace\n","\n","def remove_whitespace(text):\n"," return \" \".join(text.split())\n","text = 'This is a sample English sentence, \\n with whitespace and numbers 1234!'\n","print ('Removed whitespace: ', remove_whitespace(text))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ABN1zY708KXc","executionInfo":{"status":"ok","timestamp":1661766076806,"user_tz":-60,"elapsed":539,"user":{"displayName":"Dataset NexusTech","userId":"07175580999036037068"}},"outputId":"a8276994-5dec-4b65-8498-f0e6997660af"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Removed whitespace:  This is a sample English sentence, with whitespace and numbers 1234!\n"]}]},{"cell_type":"code","source":["a = 'this is a test'\n","\n","b = a.split()"],"metadata":{"id":"oGtbUPX8-gRq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["c= \" \".join(b)"],"metadata":{"id":"fzBCdHI6-9gQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["type(c)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LCC2QC6r_OR9","executionInfo":{"status":"ok","timestamp":1661766305571,"user_tz":-60,"elapsed":963,"user":{"displayName":"Dataset NexusTech","userId":"07175580999036037068"}},"outputId":"5ba59f86-8ba1-4d46-9881-6247357305aa"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["str"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","source":["## Part of Speech (PoS) Tagging\n","PoS tagging is the process of assigning language-specific parts of speech such as nouns,\n","verbs, adjectives, adverbs, etc., for each word in the given text"],"metadata":{"id":"tBWq4GruBzav"}},{"cell_type":"code","source":["#Example Code for PoS Tagging the Sentence and Visualizing the Sentence Tree\n","\n","from nltk import chunk\n","import nltk\n","nltk.download('maxent_treebank_pos_tagger')\n","nltk.download('treebank')\n","from nltk import chunk\n","nltk.download('popular')\n","nltk.download('maxent_treebank_pos_tagger')\n","\n","nltk.download('punkt')\n","\n","\n","tagged_sent = nltk.pos_tag(nltk.word_tokenize('This is a sample English sentence'))\n","print (tagged_sent)\n","\n","# from nltk.draw.tree import draw_trees\n","# draw_trees(tree)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TbTiEQGF_YAj","executionInfo":{"status":"ok","timestamp":1661949531434,"user_tz":-60,"elapsed":7024,"user":{"displayName":"Dataset NexusTech","userId":"07175580999036037068"}},"outputId":"c8e9343f-ad90-4cdb-81c8-4db5c3fc2b8e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package maxent_treebank_pos_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n","[nltk_data] Downloading package treebank to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/treebank.zip.\n","[nltk_data] Downloading collection 'popular'\n","[nltk_data]    | \n","[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/cmudict.zip.\n","[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n","[nltk_data]    | Downloading package genesis to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/genesis.zip.\n","[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n","[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/inaugural.zip.\n","[nltk_data]    | Downloading package movie_reviews to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n","[nltk_data]    | Downloading package names to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/names.zip.\n","[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n","[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/stopwords.zip.\n","[nltk_data]    | Downloading package treebank to /root/nltk_data...\n","[nltk_data]    |   Package treebank is already up-to-date!\n","[nltk_data]    | Downloading package twitter_samples to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n","[nltk_data]    | Downloading package omw to /root/nltk_data...\n","[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n","[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n","[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n","[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n","[nltk_data]    | Downloading package words to /root/nltk_data...\n","[nltk_data]    |   Unzipping corpora/words.zip.\n","[nltk_data]    | Downloading package maxent_ne_chunker to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n","[nltk_data]    | Downloading package punkt to /root/nltk_data...\n","[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n","[nltk_data]    | Downloading package snowball_data to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    | Downloading package averaged_perceptron_tagger to\n","[nltk_data]    |     /root/nltk_data...\n","[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n","[nltk_data]    | \n","[nltk_data]  Done downloading collection popular\n","[nltk_data] Downloading package maxent_treebank_pos_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package maxent_treebank_pos_tagger is already up-to-\n","[nltk_data]       date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n"]},{"output_type":"stream","name":"stdout","text":["[('This', 'DT'), ('is', 'VBZ'), ('a', 'DT'), ('sample', 'JJ'), ('English', 'JJ'), ('sentence', 'NN')]\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data]   Package punkt is already up-to-date!\n"]}]},{"cell_type":"code","source":["tagged_sent[0][1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"tE8z4MynkIey","executionInfo":{"status":"ok","timestamp":1661943749732,"user_tz":-60,"elapsed":490,"user":{"displayName":"Dataset NexusTech","userId":"07175580999036037068"}},"outputId":"8b1eef77-fdee-4892-e0a5-0dac3e58c65e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'DT'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["\n","tree = chunk.ne_chunk(tagged_sent)\n","tree.draw() # this will draw the sentence \n"],"metadata":{"id":"C2WH2HJYCFB-","colab":{"base_uri":"https://localhost:8080/","height":344},"executionInfo":{"status":"error","timestamp":1661938000637,"user_tz":-60,"elapsed":867,"user":{"displayName":"Dataset NexusTech","userId":"07175580999036037068"}},"outputId":"5b3b0c2f-fbec-48f3-a218-02b4c75d8e3d"},"execution_count":null,"outputs":[{"output_type":"error","ename":"TclError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTclError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-15d7083ee296>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mne_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtagged_sent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# this will draw the sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/tree/tree.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdraw_trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m         \u001b[0mdraw_trees\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpretty_print\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhighlight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/draw/tree.py\u001b[0m in \u001b[0;36mdraw_trees\u001b[0;34m(*trees)\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m     \"\"\"\n\u001b[0;32m-> 1008\u001b[0;31m     \u001b[0mTreeView\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1009\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/draw/tree.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *trees)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trees\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_top\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_top\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"NLTK\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_top\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<Control-x>\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdestroy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/tkinter/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, screenName, baseName, className, useTk, sync, use)\u001b[0m\n\u001b[1;32m   2021\u001b[0m                 \u001b[0mbaseName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseName\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2022\u001b[0m         \u001b[0minteractive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2023\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tkinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreenName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteractive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwantobjects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msync\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2024\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2025\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loadtk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTclError\u001b[0m: no display name and no $DISPLAY environment variable"]}]},{"cell_type":"code","source":["#Example Code for Using Perceptron Tagger and Getting Help on Tags\n","\n","# To use PerceptronTagger\n","from nltk.tag.perceptron import PerceptronTagger\n","PT = PerceptronTagger()\n","\n","print (PT.tag('This is a sample English sentence'.split()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mDa34PswOVq5","executionInfo":{"status":"ok","timestamp":1661938139142,"user_tz":-60,"elapsed":462,"user":{"displayName":"Dataset NexusTech","userId":"07175580999036037068"}},"outputId":"11dce150-07bd-4beb-90c3-0ab92253e7dc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[('This', 'DT'), ('is', 'VBZ'), ('a', 'DT'), ('sample', 'JJ'), ('English', 'JJ'), ('sentence', 'NN')]\n"]}]},{"cell_type":"markdown","source":["Note:  these are the 'modified' tags used for Penn tree banking; these are the tags used in the Jet system. NP, NPS, PP, and PP from the original Penn part-of-speech tagging were changed to NNP, NNPS, PRP, and PRP to avoid clashes with standard syntactic categories.\n","\n","\t1.\tCC\tCoordinating conjunction\n","\t2.\tCD\tCardinal number\n","\t3.\tDT\tDeterminer\n","\t4.\tEX\tExistential there\n","\t5.\tFW\tForeign word\n","\t6.\tIN\tPreposition or subordinating conjunction\n","\t7.\tJJ\tAdjective\n","\t8.\tJJR\tAdjective, comparative\n","\t9.\tJJS\tAdjective, superlative\n","\t10.\tLS\tList item marker\n","\t11.\tMD\tModal\n","\t12.\tNN\tNoun, singular or mass\n","\t13.\tNNS\tNoun, plural\n","\t14.\tNNP\tProper noun, singular\n","\t15.\tNNPS\tProper noun, plural\n","\t16.\tPDT\tPredeterminer\n","\t17.\tPOS\tPossessive ending\n","\t18.\tPRP\tPersonal pronoun\n","\t19.\tPRP$\tPossessive pronoun\n","\t20.\tRB\tAdverb\n","\t21.\tRBR\tAdverb, comparative\n","\t22.\tRBS\tAdverb, superlative\n","\t23.\tRP\tParticle\n","\t24.\tSYM\tSymbol\n","\t25.\tTO\tto\n","\t26.\tUH\tInterjection\n","\t27.\tVB\tVerb, base form\n","\t28.\tVBD\tVerb, past tense\n","\t29.\tVBG\tVerb, gerund or present participle\n","\t30.\tVBN\tVerb, past participle\n","\t31.\tVBP\tVerb, non-3rd person singular present\n","\t32.\tVBZ\tVerb, 3rd person singular present\n","\t33.\tWDT\tWh-determiner\n","\t34.\tWP\tWh-pronoun\n","\t35.\tWP$\tPossessive wh-pronoun\n","\t36.\tWRB\tWh-adverb"],"metadata":{"id":"0gvChuCpP0Xq"}},{"cell_type":"markdown","source":["## Stemming\n","Stemming is the process of transforming to the root word. It uses an algorithm that\n","removes common word endings for English words, such as “ly,” “es,” “ed,” and “s.”"],"metadata":{"id":"w2jfHUZAQ6wn"}},{"cell_type":"code","source":["#Example Code for Stemming\n","\n","from nltk import PorterStemmer, LancasterStemmer, SnowballStemmer\n","\n","# Function to apply stemming to a list of words\n","def words_stemmer(words, type=\"PorterStemmer\", lang=\"english\", encoding=\"utf8\"):\n","    supported_stemmers = [\"PorterStemmer\",\"LancasterStemmer\",\"SnowballStemmer\"]\n","    if type is False or type not in supported_stemmers:\n","        return words\n","    else:\n","        stem_words = []\n","        if type == \"PorterStemmer\":\n","            stemmer = PorterStemmer()\n","            for word in words:\n","                stem_words.append(stemmer.stem(word).encode(encoding))\n","        if type == \"LancasterStemmer\":\n","            stemmer = LancasterStemmer()\n","            for word in words:\n","                stem_words.append(stemmer.stem(word).encode(encoding))\n","        if type == \"SnowballStemmer\":\n","            stemmer = SnowballStemmer(lang)\n","            for word in words:\n","                stem_words.append(stemmer.stem(word).encode(encoding))\n","        return b\" \".join(stem_words)    #the b prefix was added cause of bytes in the iterable/it was a byte object\n","    \n","words =  'caring cares cared caringly carefully'  \n","\n","print(\"Original: \", words)\n","\n","print (\"Porter: \", words_stemmer(nltk.word_tokenize(words), \"PorterStemmer\"))\n","\n","print (\"Lancaster: \", words_stemmer(nltk.word_tokenize(words), \"LancasterStemmer\"))\n","\n","print (\"Snowball: \", words_stemmer(nltk.word_tokenize(words), \"SnowballStemmer\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_As31EN6O3mq","executionInfo":{"status":"ok","timestamp":1661941113813,"user_tz":-60,"elapsed":6,"user":{"displayName":"Dataset NexusTech","userId":"07175580999036037068"}},"outputId":"8c0eba30-bcc7-49f1-ad21-50f34167ae87"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Original:  caring cares cared caringly carefully\n","Porter:  b'care care care caringli care'\n","Lancaster:  b'car car car car car'\n","Snowball:  b'care care care care care'\n"]}]},{"cell_type":"markdown","source":["## Lemmatization\n","It is the process of transforming to the dictionary base form. For this you can use\n","WordNet, which is a large lexical database for English words that are linked together by\n","their semantic relationships. It works as a thesaurus: it groups words together based on\n","their meaning"],"metadata":{"id":"rDm_bUL0hIyk"}},{"cell_type":"code","source":[],"metadata":{"id":"ez0feVzhRvKl"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bGQAfRW0X7z3","outputId":"d81c7618-9dfd-4e79-b3f2-c0b7d132f440","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661943221868,"user_tz":-60,"elapsed":523,"user":{"displayName":"Dataset NexusTech","userId":"07175580999036037068"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Lemmatized:  b'care care care caringly carefully'\n"]}],"source":["# Example Code for Lemmatization\n","from nltk.stem import WordNetLemmatizer\n","\n","wordnet_lemmatizer = WordNetLemmatizer()\n","\n","# Function to apply lemmatization to a list of words\n","def words_lemmatizer(text, encoding=\"utf8\"):\n","    words = nltk.word_tokenize(text)\n","    lemma_words = []\n","    wl = WordNetLemmatizer()\n","    for word in words:\n","        pos = find_pos(word)\n","        lemma_words.append(wl.lemmatize(word, pos).encode(encoding))\n","    return b\" \".join(lemma_words)\n","\n","# Function to find part of speech tag for a word\n","def find_pos(word):\n","  \n","    # Part of Speech constants\n","    # ADJ, ADJ_SAT, ADV, NOUN, VERB = 'a', 's', 'r', 'n', 'v'\n","    # You can learn more about these at http://wordnet.princeton.edu/wordnet/man/wndb.5WN.html#sect3\n","    # You can learn more about all the penn tree tags at https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n","\n","    pos = nltk.pos_tag(nltk.word_tokenize(word))[0][1]\n","    # Adjective tags - 'JJ', 'JJR', 'JJS'    \n","    if pos.lower()[0] == 'j':\n","        return 'a'\n","    # Adverb tags - 'RB', 'RBR', 'RBS'\n","    elif pos.lower()[0] == 'r':\n","        return 'r'\n","    # Verb tags - 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ'\n","    elif pos.lower()[0] == 'v': \n","        return 'v'\n","    # Noun tags - 'NN', 'NNS', 'NNP', 'NNPS'\n","    else:\n","        return 'n'\n","\n","print (\"Lemmatized: \", words_lemmatizer(words))"]},{"cell_type":"markdown","source":["In the preceding case,'caringly'/'carefully' are inflected forms of care\n","and they are an entry word listed in WordNet Dictionary so they are\n","retained in their actual form itself"],"metadata":{"id":"eV93No79ibWa"}},{"cell_type":"code","source":["# Example Code for Wordnet\n","\n","from nltk.corpus import wordnet\n","syns = wordnet.synsets(\"good\")\n","\n","print (\"Definition: \", syns[0].definition())\n","print (\"Example: \", syns[0].examples())\n","\n","synonyms = []\n","antonyms = []\n","\n","# Print synonums and antonyms (having opposite meaning words)\n","for syn in wordnet.synsets(\"good\"):\n"," for l in syn.lemmas():\n","   synonyms.append(l.name())\n","   if l.antonyms():\n","     antonyms.append(l.antonyms()[0].name())\n","\n","\n","print (\"synonyms: \\n\", set(synonyms))\n","print (\"antonyms: \\n\", set(antonyms))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0-BWDK-SiNmC","executionInfo":{"status":"ok","timestamp":1661944262547,"user_tz":-60,"elapsed":11,"user":{"displayName":"Dataset NexusTech","userId":"07175580999036037068"}},"outputId":"49983b2c-534d-46e2-8e23-42b32e76196c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Definition:  benefit\n","Example:  ['for your own good', \"what's the good of worrying?\"]\n","synonyms: \n"," {'adept', 'trade_good', 'goodness', 'in_effect', 'serious', 'respectable', 'unspoiled', 'near', 'right', 'soundly', 'skilful', 'unspoilt', 'ripe', 'just', 'estimable', 'safe', 'honorable', 'secure', 'commodity', 'salutary', 'beneficial', 'skillful', 'full', 'honest', 'undecomposed', 'effective', 'proficient', 'expert', 'dependable', 'dear', 'well', 'in_force', 'sound', 'upright', 'thoroughly', 'good', 'practiced'}\n","antonyms: \n"," {'badness', 'evilness', 'evil', 'ill', 'bad'}\n"]}]},{"cell_type":"markdown","source":["## N-grams\n","One of the important concepts in text mining is n-grams, which are fundamentally a set\n","of cooccurring or continuous sequence of n items from a given sequence of large text.\n","The items here could be words, letters, and syllables"],"metadata":{"id":"-Gpqx0s25w-8"}},{"cell_type":"code","source":["# Example Code for Extracting n-grams from the Sentence\n","\n","from nltk.util import ngrams\n","from collections import Counter\n","\n","# Function to extract n-grams from text\n","def get_ngrams(text, n):\n"," n_grams = ngrams(nltk.word_tokenize(text), n)\n"," return [ ' '.join(grams) for grams in n_grams]\n"," \n","text = 'This is a sample English sentence'\n","print (\"1-gram: \", get_ngrams(text, 1))\n","print (\"2-gram: \", get_ngrams(text, 2))\n","print (\"3-gram: \", get_ngrams(text, 3))\n","print (\"4-gram: \", get_ngrams(text, 4))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c2LFzfl4nd3q","executionInfo":{"status":"ok","timestamp":1661949543017,"user_tz":-60,"elapsed":367,"user":{"displayName":"Dataset NexusTech","userId":"07175580999036037068"}},"outputId":"ba74446d-ab61-4d35-8090-e384e7c78eb9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1-gram:  ['This', 'is', 'a', 'sample', 'English', 'sentence']\n","2-gram:  ['This is', 'is a', 'a sample', 'sample English', 'English sentence']\n","3-gram:  ['This is a', 'is a sample', 'a sample English', 'sample English sentence']\n","4-gram:  ['This is a sample', 'is a sample English', 'a sample English sentence']\n"]}]},{"cell_type":"markdown","source":["1-gram is also called a unigram; 2-gram and 3-gram are bigram and\n","trigram, respectively.\n","\n","N-gram technique is relatively simple, and simply increasing the value of n will give\n","us more contexts. It is widely used in probabilistic language models for predicting the\n","next item in a sequence. For example, search engines use this technique to predict/\n","recommend the possibility of next character/words in the sequence for the user as they\n","type"],"metadata":{"id":"xaVQZoMf7r2s"}},{"cell_type":"code","source":["#Example Code for Extracting 2-grams from the Sentence and Storing in a Dataframe\n","\n","text = 'Statistics skills, and programming skills are equally important for analytics. Statistics skills and domain knowledge are important for analytics'\n","\n","# remove punctuations\n","text = remove_punctuations(text)\n","\n","# Extracting bigrams\n","result = get_ngrams(text,2)\n","\n","# Counting bigrams\n","result_count = Counter(result)\n","\n","# Converting the result to a data frame\n","import pandas as pd\n","df = pd.DataFrame.from_dict(result_count, orient='index')\n","df = df.rename(columns={'index':'words', 0:'frequency'}) # Renaming index and column name\n","\n","df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":488},"id":"B1oQHPaY6CEe","executionInfo":{"status":"ok","timestamp":1661950227202,"user_tz":-60,"elapsed":10,"user":{"displayName":"Dataset NexusTech","userId":"07175580999036037068"}},"outputId":"1b67ea2b-2465-45b7-f4d4-314347623af6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                      frequency\n","Statistics skills             2\n","skills and                    2\n","and programming               1\n","programming skills            1\n","skills are                    1\n","are equally                   1\n","equally important             1\n","important for                 2\n","for analytics                 2\n","analytics Statistics          1\n","and domain                    1\n","domain knowledge              1\n","knowledge are                 1\n","are important                 1"],"text/html":["\n","  <div id=\"df-3b7fd2fa-9bee-42ac-9a37-13a58cda7687\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>frequency</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Statistics skills</th>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>skills and</th>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>and programming</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>programming skills</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>skills are</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>are equally</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>equally important</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>important for</th>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>for analytics</th>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>analytics Statistics</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>and domain</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>domain knowledge</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>knowledge are</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>are important</th>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3b7fd2fa-9bee-42ac-9a37-13a58cda7687')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3b7fd2fa-9bee-42ac-9a37-13a58cda7687 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3b7fd2fa-9bee-42ac-9a37-13a58cda7687');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["result_count"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dWBlYURR8KBC","executionInfo":{"status":"ok","timestamp":1661950189221,"user_tz":-60,"elapsed":445,"user":{"displayName":"Dataset NexusTech","userId":"07175580999036037068"}},"outputId":"e50e51d4-fca5-4953-f86c-287121195c81"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Counter({'Statistics skills': 2,\n","         'skills and': 2,\n","         'and programming': 1,\n","         'programming skills': 1,\n","         'skills are': 1,\n","         'are equally': 1,\n","         'equally important': 1,\n","         'important for': 2,\n","         'for analytics': 2,\n","         'analytics Statistics': 1,\n","         'and domain': 1,\n","         'domain knowledge': 1,\n","         'knowledge are': 1,\n","         'are important': 1})"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":[],"metadata":{"id":"z2mISNhz81fy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Bag of Words\n","The texts have to be represented as numbers to be able to apply any algorithms. Bag of\n","words (BoW) is the method where you count the occurrence of words in a document\n","without giving importance to the grammar and the order of words. This can be achieved\n","by creating the Term-Document Matrix (TDM). It is simply a matrix with terms as the\n","rows, document names as the columns, and a count of the frequency of words as the\n","cells of the matrix"],"metadata":{"id":"uTWMmXspAK_k"}},{"cell_type":"code","source":["#Creating a Term Document Matrix from a Corpus of Sample Documents\n","\n","import os\n","import pandas as pd\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","\n","# Function to create a dictionary with key as file names and values as text for all files in a given folder\n","def CorpusFromDir(dir_path):\n"," result = dict(docs = [open(os.path.join(dir_path,f)).read() for f in os.listdir(dir_path)],ColNames = map(lambda x: x, os.listdir(dir_path)))\n"," \n"," return result\n","\n","\n","docs = CorpusFromDir('/content/drive/MyDrive/DS Specializations/ML/Machine Learning Specialization Script Files/Datasets/text_files')\n","print(docs)\n","# Initialize\n","vectorizer = CountVectorizer()\n","doc_vec = vectorizer.fit_transform(docs.get('docs'))\n","\n","#create dataFrame\n","df = pd.DataFrame(doc_vec.toarray().transpose(), index = vectorizer.get_feature_names_out())\n","\n","# Change column headers to be file names\n","df.columns = docs.get('ColNames')\n","\n","a = df.columns\n","print (df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XU9eDRndAOfV","executionInfo":{"status":"ok","timestamp":1667290599813,"user_tz":-60,"elapsed":415,"user":{"displayName":"Dataset NexusTech","userId":"07175580999036037068"}},"outputId":"afd3a4ed-d277-479e-a885-ac9b6310c09d"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["{'docs': ['Statistics skills, and domain knowledge are important for analytics.', 'I like reading books and travelling.', 'Statistics skills, and programming skills are equally important for analytics.'], 'ColNames': <map object at 0x7efc973b0990>}\n","             Doc_2.txt  Doc_3.txt  Doc_1.txt\n","analytics            1          0          1\n","and                  1          1          1\n","are                  1          0          1\n","books                0          1          0\n","domain               1          0          0\n","equally              0          0          1\n","for                  1          0          1\n","important            1          0          1\n","knowledge            1          0          0\n","like                 0          1          0\n","programming          0          0          1\n","reading              0          1          0\n","skills               1          0          2\n","statistics           1          0          1\n","travelling           0          1          0\n"]}]},{"cell_type":"code","source":["docs.get('ColNames')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8r3T5Q97J4Ru","executionInfo":{"status":"ok","timestamp":1667288788165,"user_tz":-60,"elapsed":591,"user":{"displayName":"Dataset NexusTech","userId":"07175580999036037068"}},"outputId":"32844577-a0a7-4cda-99c5-461ddcde920b"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<map at 0x7efcaa39fa90>"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["a"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zFDChFU_KH3S","executionInfo":{"status":"ok","timestamp":1667290618614,"user_tz":-60,"elapsed":501,"user":{"displayName":"Dataset NexusTech","userId":"07175580999036037068"}},"outputId":"4ddd0c67-9bf4-4498-a120-5f17614dd921"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['Doc_2.txt', 'Doc_3.txt', 'Doc_1.txt'], dtype='object')"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["The Term Document Matrix (TDM) is the transpose of the term-document\n","matrix. In TDM, the rows will be the document names and column headers will\n","be the term"],"metadata":{"id":"_J69Bbq2098c"}},{"cell_type":"markdown","source":["## Term Frequency-Inverse Document Frequency (TF-IDF)\n","In the area of information retrieval, TF-IDF is a good statistical measure to reflect the\n","relevance of the term to the document in a collection of documents or corpus"],"metadata":{"id":"2-6Vg7lR8MqD"}},{"cell_type":"code","source":["# Create a Term Document Matrix (TDM) with TF-IDF\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","vectorizer = TfidfVectorizer()\n","doc_vec = vectorizer.fit_transform(docs.get('docs'))\n","\n","#create dataFrame\n","df = pd.DataFrame(doc_vec.toarray().transpose(), index = vectorizer.get_feature_names_out())\n","\n","# Change column headers to be file names\n","df.columns = a\n","print (df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gbl09l9m0QFw","executionInfo":{"status":"ok","timestamp":1667290626153,"user_tz":-60,"elapsed":527,"user":{"displayName":"Dataset NexusTech","userId":"07175580999036037068"}},"outputId":"83acbd1f-6b03-4ea8-d8d0-0c704c78de20"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["             Doc_2.txt  Doc_3.txt  Doc_1.txt\n","analytics     0.315269   0.000000   0.276703\n","and           0.244835   0.283217   0.214884\n","are           0.315269   0.000000   0.276703\n","books         0.000000   0.479528   0.000000\n","domain        0.414541   0.000000   0.000000\n","equally       0.000000   0.000000   0.363831\n","for           0.315269   0.000000   0.276703\n","important     0.315269   0.000000   0.276703\n","knowledge     0.414541   0.000000   0.000000\n","like          0.000000   0.479528   0.000000\n","programming   0.000000   0.000000   0.363831\n","reading       0.000000   0.479528   0.000000\n","skills        0.315269   0.000000   0.553405\n","statistics    0.315269   0.000000   0.276703\n","travelling    0.000000   0.479528   0.000000\n"]}]},{"cell_type":"code","source":["df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":519},"id":"1X-5ySnA9LzH","executionInfo":{"status":"ok","timestamp":1662034560845,"user_tz":-60,"elapsed":451,"user":{"displayName":"Dataset NexusTech","userId":"07175580999036037068"}},"outputId":"0bfaaa50-b7b0-4c90-cd18-c80e3d3221ab"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                    0         1         2\n","analytics    0.315269  0.000000  0.276703\n","and          0.244835  0.283217  0.214884\n","are          0.315269  0.000000  0.276703\n","books        0.000000  0.479528  0.000000\n","domain       0.414541  0.000000  0.000000\n","equally      0.000000  0.000000  0.363831\n","for          0.315269  0.000000  0.276703\n","important    0.315269  0.000000  0.276703\n","knowledge    0.414541  0.000000  0.000000\n","like         0.000000  0.479528  0.000000\n","programming  0.000000  0.000000  0.363831\n","reading      0.000000  0.479528  0.000000\n","skills       0.315269  0.000000  0.553405\n","statistics   0.315269  0.000000  0.276703\n","travelling   0.000000  0.479528  0.000000"],"text/html":["\n","  <div id=\"df-fc7d328f-5f1b-4afd-8a11-f1f3ad8b8789\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>analytics</th>\n","      <td>0.315269</td>\n","      <td>0.000000</td>\n","      <td>0.276703</td>\n","    </tr>\n","    <tr>\n","      <th>and</th>\n","      <td>0.244835</td>\n","      <td>0.283217</td>\n","      <td>0.214884</td>\n","    </tr>\n","    <tr>\n","      <th>are</th>\n","      <td>0.315269</td>\n","      <td>0.000000</td>\n","      <td>0.276703</td>\n","    </tr>\n","    <tr>\n","      <th>books</th>\n","      <td>0.000000</td>\n","      <td>0.479528</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>domain</th>\n","      <td>0.414541</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>equally</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.363831</td>\n","    </tr>\n","    <tr>\n","      <th>for</th>\n","      <td>0.315269</td>\n","      <td>0.000000</td>\n","      <td>0.276703</td>\n","    </tr>\n","    <tr>\n","      <th>important</th>\n","      <td>0.315269</td>\n","      <td>0.000000</td>\n","      <td>0.276703</td>\n","    </tr>\n","    <tr>\n","      <th>knowledge</th>\n","      <td>0.414541</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>like</th>\n","      <td>0.000000</td>\n","      <td>0.479528</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>programming</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.363831</td>\n","    </tr>\n","    <tr>\n","      <th>reading</th>\n","      <td>0.000000</td>\n","      <td>0.479528</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>skills</th>\n","      <td>0.315269</td>\n","      <td>0.000000</td>\n","      <td>0.553405</td>\n","    </tr>\n","    <tr>\n","      <th>statistics</th>\n","      <td>0.315269</td>\n","      <td>0.000000</td>\n","      <td>0.276703</td>\n","    </tr>\n","    <tr>\n","      <th>travelling</th>\n","      <td>0.000000</td>\n","      <td>0.479528</td>\n","      <td>0.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fc7d328f-5f1b-4afd-8a11-f1f3ad8b8789')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-fc7d328f-5f1b-4afd-8a11-f1f3ad8b8789 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-fc7d328f-5f1b-4afd-8a11-f1f3ad8b8789');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["print (a)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JvlvoSrP98Ju","executionInfo":{"status":"ok","timestamp":1662034432103,"user_tz":-60,"elapsed":786,"user":{"displayName":"Dataset NexusTech","userId":"07175580999036037068"}},"outputId":"5ea7b116-5a43-4253-cbcf-5cabbab13bd2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<map object at 0x7f906aa68b10>\n"]}]},{"cell_type":"code","source":["os.listdir('/content/drive/MyDrive/Machine Learning Specialization Script Files/Datasets/text_files')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EXBtH2Nu-Mrp","executionInfo":{"status":"ok","timestamp":1662035429191,"user_tz":-60,"elapsed":464,"user":{"displayName":"Dataset NexusTech","userId":"07175580999036037068"}},"outputId":"e348e802-c91f-4e21-8d87-db5b5da007ce"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Doc_2.txt', 'Doc_3.txt', 'Doc_1.txt']"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["print (b)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k9JwwSbTAuSZ","executionInfo":{"status":"ok","timestamp":1662035353533,"user_tz":-60,"elapsed":711,"user":{"displayName":"Dataset NexusTech","userId":"07175580999036037068"}},"outputId":"122028eb-d187-4433-aa8f-e0bfa9c064d9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["None\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"1Cu7ryeaBOqy"},"execution_count":null,"outputs":[]}]}